{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"any-agent","text":"<p><code>any-agent</code> is a Python library providing a single interface to different agent frameworks.</p> <p>Warning</p> <p>Compared to traditional code-defined workflows, agent frameworks introduce complexity, additional security implications to consider, and demand much more computational power.</p> <p>Before jumping to use one, carefully consider and evaluate how much value you would get compared to manually defining a sequence of tools and LLM calls.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>You can install the bare bones library as follows (only <code>TinyAgent</code> will be available):</p> <pre><code>pip install any-agent\n</code></pre> <p>Or you can install it with the required dependencies for one of more frameworks:</p> <pre><code>pip install any-agent[agno,openai]\n</code></pre> <p>Refer to pyproject.toml for a list of the options available.</p>"},{"location":"agents/","title":"Agents","text":""},{"location":"agents/#defining-agents","title":"Defining Agents","text":"<p>To define any agent system you will always use the same imports:</p> <pre><code>from any_agent import AgentConfig, AnyAgent\n# In these examples, the built-in tools will be used\nfrom any_agent.tools import search_web, visit_webpage\n</code></pre> <p>Check <code>AgentConfig</code> for more info on how to configure agents.</p>"},{"location":"agents/#single-agent","title":"Single Agent","text":"<pre><code>agent = AnyAgent.create(\n    \"openai\",  # See other options under `Frameworks`\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"Use the tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    ),\n)\n</code></pre>"},{"location":"agents/#multi-agent","title":"Multi-Agent","text":"<p>Warning</p> <p>A multi-agent system introduces even more complexity than a single agent.</p> <p>As stated before, carefully consider whether you need to adopt this pattern to solve the task.</p> <pre><code>agent = AnyAgent.create(\n    \"openai\",  # See other options under `Frameworks`\n    AgentConfig(\n        model_id=\"gpt-4.1-mini\",\n        instructions=\"You are the main agent. Use the other available agents to find an answer\",\n    ),\n    managed_agents=[\n        AgentConfig(\n            name=\"search_web_agent\",\n            description=\"An agent that can search the web\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[search_web]\n        ),\n        AgentConfig(\n            name=\"visit_webpage_agent\",\n            description=\"An agent that can visit webpages\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[visit_webpage]\n        )\n    ]\n)\n</code></pre>"},{"location":"agents/#running-agents","title":"Running Agents","text":"<p>Regardless of the definition (single-agent or multi-agent), you can run the agent as follows:</p> <pre><code>agent_trace = agent.run(\"Which Agent Framework is the best??\")\nprint(agent_trace.final_output)\n</code></pre> <p>Check <code>AgentTrace</code> for more info on the return type.</p>"},{"location":"agents/#async","title":"Async","text":"<p>If you are running in <code>async</code> context, you should use the equivalent <code>create_async</code> and <code>run_async</code> methods:</p> <pre><code>import asyncio\n\nasync def main():\n    agent = await AnyAgent.create_async(\n        \"openai\",\n        AgentConfig(\n            model_id=\"gpt-4.1-mini\",\n            instructions=\"You are the main agent. Use the other available agents to find an answer\",\n        ),\n        managed_agents=[\n            AgentConfig(\n                name=\"search_web_agent\",\n                description=\"An agent that can search the web\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[search_web]\n            ),\n            AgentConfig(\n                name=\"visit_webpage_agent\",\n                description=\"An agent that can visit webpages\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[visit_webpage]\n            )\n        ]\n    )\n\n    agent_trace = await agent.run_async(\"Which Agent Framework is the best??\")\n    print(agent_trace.final_output)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"agents/#cleaning-up-the-agent","title":"Cleaning up the Agent","text":"<p>When an AnyAgent object is deleted, the python garbage collector cleans up any resources owned by the object. However, when running or re-creating an agent in the same python process (for example, in test scripts) it may be necessary to forcefully shut down the agent to avoid unexpected side affects. For this purpose, <code>agent.exit</code> is available which will shut down all resources the agent was using.</p> <p>For example,</p> <pre><code>agent.run(\"Which agent framework is the best?\")\nagent.exit() # cleans up the agent synchronously\n</code></pre>"},{"location":"evaluation/","title":"Agent Evaluation","text":"<p>Warning</p> <p>The codebase for evaluation is under development and is not yet stable. Use with caution, we welcome contributions.</p> <p>Evaluation using any_agent.evaluation is designed to be a \"trace-first\" evaluation. The evaluation of a trace is not designed to be pass/fail, but is rather a score based on the achievement of user-defined criteria for each example. Agent systems are hyper-specific to each use case, and it's difficult to provide a single set of metrics that would reliably provide the insight needed to make a decision about the effectiveness of an agent.</p> <p>Using any-agent evaluation, you can specify any criteria you wish, and through the LLM-as-a-judge technique, any-agent will evaluate which criteria are satisfied.</p>"},{"location":"evaluation/#example","title":"Example","text":"<p>Using the unified tracing format provided by any-agent's tracing functionality, the trace can be evaluated with user defined criteria. The steps for evaluating an agent are as follows:</p>"},{"location":"evaluation/#run-an-agent-using-any-agent-which-will-produce-a-trace-for-example","title":"Run an agent using any-agent, which will produce a trace. For example","text":"<pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\",\n        tools=[search_web]\n    ),\n    tracing=TracingConfig(console=True, cost_info=False)\n)\n\nagent_trace = agent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\n</code></pre>"},{"location":"evaluation/#define-an-evaluation-case-either-in-a-yaml-file-or-in-python","title":"Define an evaluation case either in a yaml file or in python:","text":"YAMLPython <p><pre><code># The criteria will be passed to an llm-as-a-judge along with the trace to have as context\n# The points specify the weight given to each criteria when producing the final score\nllm_judge: openai/gpt-4o\ncheckpoints:\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n  - points: 1\n    criteria: |\n        Ensure that the agent ran a python snippet to combine the information\n        from the info retrieved from the web searches\n\n# Optionally, you can check whether the final answer is what was expected. Checking this value does not use an LLM\nground_truth:\n  - name: Time\n    points: 5\n    value: 9.63\n</code></pre> Then in python <pre><code>from any_agent.evaluation.evaluation_case import EvaluationCase\nevaluation_case = EvaluationCase.from_yaml(evaluation_case_path)\n</code></pre></p> <pre><code>from any_agent.evaluation.evaluation_case import EvaluationCase\nevaluation_case = EvaluationCase(\n        ground_truth=[{\"name\": \"Seconds\", \"value\": \"9\", \"points\": 1.0}],\n        checkpoints=[\n            {\"criteria\": \"Did the agent run a calculation\", \"points\": 1},\n            {\"criteria\": \"Did the agent use fewer than 5 steps\", \"points\": 4},\n        ],\n        llm_judge=\"gpt-4o-mini\",\n)\n</code></pre>"},{"location":"evaluation/#run-the-evaluation-using-the-test-case-and-trace","title":"Run the evaluation using the test case and trace.","text":"<pre><code>from any_agent.evaluation import evaluate, EvaluationCase\nevaluation_case = EvaluationCase(\n    ground_truth=[{\"name\": \"Test Case 1\", \"value\": 1.0, \"points\": 1.0}],\n    checkpoints=[{\"criteria\": \"Check if value is 1.0\", \"points\": 1}],\n    llm_judge=\"gpt-4o-mini\",\n)\neval_result = evaluate(\n    evaluation_case=evaluation_case,\n    trace=agent_trace,\n    agent_framework=\"OPENAI\",\n)\nprint(f\"Final score: {eval_result.score}\")\n</code></pre>"},{"location":"evaluation/#command-line","title":"Command Line","text":"<p>If you have the file and test case prepared, a command line tools is provided for convenience called <code>any-agent-evaluate</code>.</p> <p>It can be called like so</p> <pre><code>any-agent-evaluate \\\n    --evaluation_case_path \"docs/examples/evaluation_case.yaml\" \\\n    --trace_path \"tests/unit/evaluation/sample_traces/OPENAI.json\" \\\n    --agent_framework 'OPENAI'\n</code></pre>"},{"location":"instructions/","title":"Agent Instructions (aka System Prompt)","text":"<p><code>any-agent</code> allows you to specify the instruction for the agent (often also referred to as a \"system_prompt\").</p> <p>Warning</p> <p>Some frameworks use complex default instructions for specific agent implementations. Completely replacing those instructions might result in unexpected behavior.</p> <p>In those cases, you might want to instead copy-paste and extend the default instructions. For example, check the <code>ToolCallingAgent</code> default instructions in <code>smolagents</code>.</p> <pre><code>from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\nfrom any_agent import AgentConfig\n\ninstruction = RECOMMENDED_PROMPT_PREFIX + \"\\nYou are a helpful assistant that can navigate the web.\"\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    instructions=instruction,\n)\n</code></pre>"},{"location":"serving/","title":"Serving (A2A)","text":"<p><code>any-agent</code> provides a simple way of serving agents from any of the supported frameworks using the Agent2Agent Protocol (A2A). You can refer to the link for more information on the protocol, as explaining it is out of the scope of this page.</p> <p>Warning</p> <p>The A2A protocol is in early stages of development and so is the functionality provided by <code>any-agent</code> here.</p> <p>You can configuring and serve an agent using the <code>ServingConfig</code> and the <code>AnyAgent.serve</code> method.</p>"},{"location":"serving/#example","title":"Example","text":"<p>Info</p> <p>Until an official SDK is released (see this issue), you need to install the A2A dependencies as follows:</p> <pre><code>pip install \"git+https://github.com/google/A2A#subdirectory=samples/python\"\n</code></pre> <p>For illustrative purposes, we are going to define 2 separate scripts, each defining an agent to answer questions about a specific agent framework (either OpenAI Agents SDK or Google ADK):</p> Google ExpertOpenAI Expert <pre><code># google_expert.py\nfrom any_agent import AgentConfig, AnyAgent\nfrom any_agent.config import ServingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n    \"google\",\n    AgentConfig(\n        name=\"google_expert\",\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        description=\"An agent that can answer questions specifically about the Google Agents Development Kit (ADK).\",\n        tools=[search_web]\n    )\n)\n\nagent.serve(ServingConfig(port=5001))\n</code></pre> <pre><code># openai_expert.py\nfrom any_agent import AgentConfig, AnyAgent\nfrom any_agent.config import ServingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        name=\"openai-expert\",\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        description=\"An agent that can answer questions specifically about the OpenAI Agents SDK.\",\n        tools=[search_web]\n    )\n)\n\nagent.serve(ServingConfig(port=5002))\n</code></pre> <p>We can then run each of the scripts in a separate terminal and leave them running in the background.</p> <p>There are multiple options to interact with these agents. We are going to use the example demo UI and follow the instructions to get it running.</p> <p>With the UI running, we can register the 2 new that are being served using their corresponding URLs:</p> Google ExpertOpenAI Expert <p></p> <p></p> <p>Now that the agents are registered, we can interact with the \"host\" agent that will (hopefully) redirect the request to the appropriate expert:</p> <p></p>"},{"location":"tools/","title":"Agent Tools","text":"<p><code>any-agent</code> provides 2 options to specify what <code>tools</code> are available to your agent: <code>Callable</code>, or <code>MCP</code> (Model Context Protocol).</p> <p>You can use any combination of options in the same agent.</p> <p>Under the hood, <code>any-agent</code> takes care of wrapping the tool so it becomes usable by the selected framework.</p> <p>MCP can either be run locally (MCPStdio) or you can connect to an MCP that is running elsewhere (MCPSse). See SuperGateway for an easy way to turn a Stdio server into an SSE server.</p> CallableMCP (Stdio)MCP (SSE) <pre><code>from any_agent import AgentConfig\nfrom any_agent.tools import search_web\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[search_web]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPStdio\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPStdio(\n            command=\"docker\",\n            args=[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n            tools=[\"fetch\"]\n        ),\n    ]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPSse\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPSse(\n            url=\"http://localhost:8000/sse\"\n        ),\n    ]\n)\n</code></pre>"},{"location":"tracing/","title":"Agent Tracing","text":"<p><code>any-agent</code> uses <code>openinference</code> to generate standardized OpenTelemetry traces for any of the supported <code>Frameworks</code>.</p> <p>An <code>AgentTrace</code> is returned when calling <code>agent.run</code> or <code>agent.run_async</code>.</p>"},{"location":"tracing/#example","title":"Example","text":"<p>By default, tracing to console and cost tracking is enabled. To configure tracing, pass a TracingConfig object <code>TracingConfig</code> when creating an agent.</p> <pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n        \"openai\",\n        agent_config=AgentConfig(\n                model_id=\"gpt-4o\",\n                tools=[search_web],\n        ),\n        tracing=TracingConfig(console=False)\n      )\nagent_trace = agent.run(\"Which agent framework is the best?\")\n</code></pre>"},{"location":"tracing/#console-output","title":"Console Output","text":"<p>Tracing will output standardized console output regardless of the framework used.</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ninput: Which agent framework is the best?\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 TOOL \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntool_name: search_web\ninput: {'query': 'best agent framework 2023'}\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ... The agent architecture came to life in March 2023, but it wasn't until a few    \u2502\n\u2502 months later that it took a grip in the open-source community. The agent landscape may still seem like a \"mad scientist\" kind of experiment, but there are \u2502\n\u2502 already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks Top 10 AI Agent Frameworks - gocodeo.com The    \u2502\n\u2502 ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog     \u2502\n\u2502 Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \"just prompt it and see what happens.\" As AI     \u2502\n\u2502 agents inch closer to production ... List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ... 3. Bee Agent Framework (IBM) Introduction:    \u2502\n\u2502 The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to  \u2502\n\u2502 integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ... Top 9  \u2502\n\u2502 AI Agent Frameworks as of April 2025 | Shakudo AutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by   \u2502\n\u2502 automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build,  \u2502\n\u2502 fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ... 10 best AI    \u2502\n\u2502 agent frameworks - blog.apify.com Best AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a      \u2502\n\u2502 scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it  \u2502\n\u2502 easier to integrate with third-party tools, handle cloud hosting, monitor ... Best 5 Frameworks To Build Multi-Agent AI Applications In this example, we   \u2502\n\u2502 specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run                       \u2502\n\u2502 reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework     \u2502\n\u2502 recently released by OpenAI. It is a lightweight multi-agent orchestration framework. Agentic Framework Showdown: We Tested 8 AI Agent Frameworks They     \u2502\n\u2502 reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of    \u2502\n\u2502 the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI;      \u2502\n\u2502 Langflow; LangGraph; LlamaIndex; n8n ... Comparing Open-Source AI Agent Frameworks - Langfuse Blog This post offers an in-depth look at some of the        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre>"},{"location":"tracing/#spans","title":"Spans","text":"<p>Here's what that returned trace spans would look like, accessible via the attribute <code>agent_trace.spans</code>:</p> <pre><code>[\n  {\n    \"name\": \"response\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xd4a8cd952e71e1d1\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:25.327409Z\",\n    \"end_time\": \"2025-04-07T10:20:26.813604Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"output.mime_type\": \"application/json\",\n      \"output.value\": \"{\\\"id\\\":\\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\",\\\"created_at\\\":1744021218.0,\\\"error\\\":null,\\\"incomplete_details\\\":null,\\\"instructions\\\":\\\"Search the web to answer\\\",\\\"metadata\\\":{},\\\"model\\\":\\\"gpt-4o-2024-08-06\\\",\\\"object\\\":\\\"response\\\",\\\"output\\\":[{\\\"arguments\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"best agent framework 2023\\\\\\\"}\\\",\\\"call_id\\\":\\\"call_xCZMfOtnbmKS1nGDywFtmCcR\\\",\\\"name\\\":\\\"search_web\\\",\\\"type\\\":\\\"function_call\\\",\\\"id\\\":\\\"fc_67f3a6e351988192a79ec42d68fccbe001e7f8b6e38c7e7a\\\",\\\"status\\\":\\\"completed\\\"}],\\\"parallel_tool_calls\\\":false,\\\"temperature\\\":1.0,\\\"tool_choice\\\":\\\"auto\\\",\\\"tools\\\":[{\\\"name\\\":\\\"search_web\\\",\\\"parameters\\\":{\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"The search query to perform.\\\",\\\"title\\\":\\\"Query\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"],\\\"title\\\":\\\"search_web_args\\\",\\\"type\\\":\\\"object\\\",\\\"additionalProperties\\\":false},\\\"strict\\\":true,\\\"type\\\":\\\"function\\\",\\\"description\\\":\\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\"}],\\\"top_p\\\":1.0,\\\"max_output_tokens\\\":null,\\\"previous_response_id\\\":null,\\\"reasoning\\\":{\\\"effort\\\":null,\\\"generate_summary\\\":null},\\\"status\\\":\\\"completed\\\",\\\"text\\\":{\\\"format\\\":{\\\"type\\\":\\\"text\\\"}},\\\"truncation\\\":\\\"disabled\\\",\\\"usage\\\":{\\\"input_tokens\\\":89,\\\"input_tokens_details\\\":{\\\"cached_tokens\\\":0},\\\"output_tokens\\\":20,\\\"output_tokens_details\\\":{\\\"reasoning_tokens\\\":0},\\\"total_tokens\\\":109},\\\"user\\\":null,\\\"store\\\":true}\",\n      \"llm.tools.0.tool.json_schema\": \"{\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"search_web\\\", \\\"description\\\": \\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\", \\\"parameters\\\": {\\\"properties\\\": {\\\"query\\\": {\\\"description\\\": \\\"The search query to perform.\\\", \\\"title\\\": \\\"Query\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"query\\\"], \\\"title\\\": \\\"search_web_args\\\", \\\"type\\\": \\\"object\\\", \\\"additionalProperties\\\": false}, \\\"strict\\\": true}}\",\n      \"llm.token_count.completion\": 89,\n      \"llm.token_count.prompt\": 20,\n      \"llm.token_count.total\": 109,\n      \"llm.output_messages.0.message.role\": \"assistant\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.id\": \"call_xCZMfOtnbmKS1nGDywFtmCcR\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.name\": \"search_web\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.arguments\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"llm.input_messages.0.message.role\": \"system\",\n      \"llm.input_messages.0.message.content\": \"Search the web to answer\",\n      \"llm.model_name\": \"gpt-4o-2024-08-06\",\n      \"llm.invocation_parameters\": \"{\\\"id\\\": \\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\", \\\"created_at\\\": 1744021218.0, \\\"instructions\\\": \\\"Search the web to answer\\\", \\\"metadata\\\": {}, \\\"model\\\": \\\"gpt-4o-2024-08-06\\\", \\\"object\\\": \\\"response\\\", \\\"parallel_tool_calls\\\": false, \\\"temperature\\\": 1.0, \\\"tool_choice\\\": \\\"auto\\\", \\\"top_p\\\": 1.0, \\\"reasoning\\\": {}, \\\"status\\\": \\\"completed\\\", \\\"text\\\": {\\\"format\\\": {\\\"type\\\": \\\"text\\\"}}, \\\"truncation\\\": \\\"disabled\\\", \\\"store\\\": true}\",\n      \"input.mime_type\": \"application/json\",\n      \"input.value\": \"[{\\\"content\\\": \\\"Which agent framework is the best?\\\", \\\"role\\\": \\\"user\\\"}]\",\n      \"llm.input_messages.1.message.role\": \"user\",\n      \"llm.input_messages.1.message.content\": \"Which agent framework is the best?\",\n      \"openinference.span.kind\": \"LLM\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n  {\n    \"name\": \"search_web\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xe8fa92007caee376\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:26.821732Z\",\n    \"end_time\": \"2025-04-07T10:20:28.420378Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"tool.name\": \"search_web\",\n      \"input.value\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"input.mime_type\": \"application/json\",\n      \"output.value\": \"[Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ...](https://www.taskade.com/blog/top-autonomous-agents/)\\nThe agent architecture came to life in March 2023, but it wasn't until a few months later that it took a grip in the open-source community. The agent landscape may still seem like a \\\"mad scientist\\\" kind of experiment, but there are already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks\\n[Top 10 AI Agent Frameworks - gocodeo.com](https://www.gocodeo.com/post/top-10-ai-agent-frameworks)\\nThe ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \\\"just prompt it and see what happens.\\\" As AI agents inch closer to production ...\\n[List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ...](https://www.devopsschool.com/blog/list-of-top-10-multi-agent-orchestrator-frameworks-for-deploying-ai-agents/)\\n3. Bee Agent Framework (IBM) Introduction: The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ...\\n[Top 9 AI Agent Frameworks as of April 2025 | Shakudo](https://www.shakudo.io/blog/top-9-ai-agent-frameworks)\\nAutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build, fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ...\\n[10 best AI agent frameworks - blog.apify.com](https://blog.apify.com/10-best-ai-agent-frameworks/)\\nBest AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it easier to integrate with third-party tools, handle cloud hosting, monitor ...\\n[Best 5 Frameworks To Build Multi-Agent AI Applications](https://getstream.io/blog/multiagent-ai-frameworks/)\\nIn this example, we specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework recently released by OpenAI. It is a lightweight multi-agent orchestration framework.\\n[Agentic Framework Showdown: We Tested 8 AI Agent Frameworks](https://www.willowtreeapps.com/craft/8-agentic-frameworks-tested)\\nThey reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI; Langflow; LangGraph; LlamaIndex; n8n ...\\n[Comparing Open-Source AI Agent Frameworks - Langfuse Blog](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)\\nThis post offers an in-depth look at some of the leading open-source AI agent frameworks out there: LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, and LlamaIndex agents. By the time you finish reading, you should have a clearer view of each framework's sweet spot, how they differ, and where they excel in real ...\\n[Choosing the Right AI Agent Framework: LangGraph vs CrewAI vs OpenAI Swarm](https://www.relari.ai/blog/ai-agent-framework-comparison-langgraph-crewai-openai-swarm)\\nWe chose LangGraph, CrewAI, and OpenAI Swarm because they represent the latest schools of thought in agent development. Here's a quick overview: LangGraph: As its name suggests, LangGraph bets on graph architecture as the best way to define and orchestrate agentic workflows. Unlike early versions of LangChain, LangGraph is a well designed framework with many robust and customizable features ...\\n[Best AI Agent Frameworks](https://www.folio3.ai/blog/ai-agent-frameworks/)\\nYour business demands the best AI agent framework to accelerate your project. It should support LLM integration, advanced reasoning, long-term memory, flexible tool coordination, and smooth collaboration between multiple agents. Here we discuss some AI agent frameworks that empower you to achieve unmatched levels of automation and intelligence.\",\n      \"openinference.span.kind\": \"TOOL\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n</code></pre>"},{"location":"tracing/#dumping-to-file","title":"Dumping to File","text":"<p>The AgentTrace object is a pydantic model and can be saved to disk via standard pydantic practices:</p> <pre><code>with open(\"output.json\", \"w\", encoding=\"utf-8\") as f:\n  f.write(agent_trace.model_dump_json(indent=2))\n</code></pre>"},{"location":"api/agent/","title":"Agent","text":""},{"location":"api/agent/#agent","title":"Agent","text":""},{"location":"api/agent/#any_agent.AnyAgent","title":"<code>any_agent.AnyAgent</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base abstract class for all agent implementations.</p> <p>This provides a unified interface for different agent frameworks.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>class AnyAgent(ABC):\n    \"\"\"Base abstract class for all agent implementations.\n\n    This provides a unified interface for different agent frameworks.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: AgentConfig,\n        managed_agents: Sequence[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ):\n        self.config = config\n        self.managed_agents = managed_agents\n\n        self._mcp_servers: list[_MCPServerBase[Any]] = []\n        self._main_agent_tools: list[Any] = []\n\n        # Tracing is enabled by default\n        self._tracing_config: TracingConfig = tracing or TracingConfig()\n        self._instrumenter: Instrumenter | None = None\n        self._setup_tracing()\n\n    @staticmethod\n    def _get_agent_type_by_framework(\n        framework_raw: AgentFramework | str,\n    ) -&gt; type[AnyAgent]:\n        framework = AgentFramework.from_string(framework_raw)\n\n        if framework is AgentFramework.SMOLAGENTS:\n            from any_agent.frameworks.smolagents import SmolagentsAgent\n\n            return SmolagentsAgent\n\n        if framework is AgentFramework.LANGCHAIN:\n            from any_agent.frameworks.langchain import LangchainAgent\n\n            return LangchainAgent\n\n        if framework is AgentFramework.OPENAI:\n            from any_agent.frameworks.openai import OpenAIAgent\n\n            return OpenAIAgent\n\n        if framework is AgentFramework.LLAMA_INDEX:\n            from any_agent.frameworks.llama_index import LlamaIndexAgent\n\n            return LlamaIndexAgent\n\n        if framework is AgentFramework.GOOGLE:\n            from any_agent.frameworks.google import GoogleAgent\n\n            return GoogleAgent\n\n        if framework is AgentFramework.AGNO:\n            from any_agent.frameworks.agno import AgnoAgent\n\n            return AgnoAgent\n\n        if framework is AgentFramework.TINYAGENT:\n            from any_agent.frameworks.tinyagent import TinyAgent\n\n            return TinyAgent\n\n        assert_never(framework)\n\n    @classmethod\n    def create(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        \"\"\"Create an agent using the given framework and config.\"\"\"\n        return asyncio.get_event_loop().run_until_complete(\n            cls.create_async(\n                agent_framework=agent_framework,\n                agent_config=agent_config,\n                managed_agents=managed_agents,\n                tracing=tracing,\n            )\n        )\n\n    @classmethod\n    async def create_async(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        \"\"\"Create an agent using the given framework and config.\"\"\"\n        agent_cls = cls._get_agent_type_by_framework(agent_framework)\n        agent = agent_cls(agent_config, managed_agents=managed_agents, tracing=tracing)\n        await agent._load_agent()\n        return agent\n\n    async def _load_tools(\n        self, tools: Sequence[Tool]\n    ) -&gt; tuple[list[Any], list[_MCPServerBase[Any]]]:\n        tools, mcp_servers = await _wrap_tools(tools, self.framework)\n        # Add to agent so that it doesn't get garbage collected\n        self._mcp_servers.extend(mcp_servers)\n        for mcp_server in mcp_servers:\n            tools.extend(mcp_server.tools)\n        return tools, mcp_servers\n\n    def _setup_tracing(self) -&gt; None:\n        \"\"\"Initialize the tracing for the agent.\"\"\"\n        self._tracer_provider = TracerProvider()\n        trace.set_tracer_provider(self._tracer_provider)\n        if not _is_tracing_supported(self.framework):\n            logger.warning(\n                \"Tracing is not yet supported for AGNO and GOOGLE frameworks. \"\n            )\n            self._instrumenter = None\n            return\n        self._exporter = AnyAgentExporter(self.framework, self._tracing_config)\n        self._tracer_provider.add_span_processor(SimpleSpanProcessor(self._exporter))\n        self._instrumenter = get_instrumenter_by_framework(self.framework)\n        self._instrumenter.instrument(tracer_provider=self._tracer_provider)\n\n    def run(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n        \"\"\"Run the agent with the given prompt.\"\"\"\n        return asyncio.get_event_loop().run_until_complete(\n            self.run_async(prompt, **kwargs)\n        )\n\n    def serve(self, serving_config: ServingConfig | None = None) -&gt; None:\n        \"\"\"Serve this agent using the Agent2Agent Protocol (A2A).\n\n        Args:\n            serving_config: See [ServingConfig][any_agent.config.ServingConfig].\n\n        Raises:\n            ImportError: If the `serving` dependencies are not installed.\n\n        \"\"\"\n        try:\n            from any_agent.serving import _get_a2a_server\n        except ImportError as e:\n            msg = \"You need to `pip install 'git+https://github.com/google/A2A#subdirectory=samples/python' to use this method.\"\n            raise ImportError(msg) from e\n\n        server = _get_a2a_server(self, serving_config=serving_config or ServingConfig())\n        server.start()\n\n    @abstractmethod\n    async def _load_agent(self) -&gt; None:\n        \"\"\"Load the agent instance.\"\"\"\n\n    @abstractmethod\n    async def run_async(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n        \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n\n    @property\n    @abstractmethod\n    def framework(self) -&gt; AgentFramework:\n        \"\"\"The Agent Framework used.\"\"\"\n\n    @property\n    def agent(self) -&gt; Any:\n        \"\"\"The underlying agent implementation from the framework.\n\n        This property is intentionally restricted to maintain framework abstraction\n        and prevent direct dependency on specific agent implementations.\n\n        If you need functionality that relies on accessing the underlying agent:\n        1. Consider if the functionality can be added to the AnyAgent interface\n        2. Submit a GitHub issue describing your use case\n        3. Contribute a PR implementing the needed functionality\n\n        Raises:\n            NotImplementedError: Always raised when this property is accessed\n\n        \"\"\"\n        msg = \"Cannot access the 'agent' property of AnyAgent, if you need to use functionality that relies on the underlying agent framework, please file a Github Issue or we welcome a PR to add the functionality to the AnyAgent class\"\n        raise NotImplementedError(msg)\n\n    def exit(self) -&gt; None:\n        \"\"\"Exit the agent and clean up resources.\"\"\"\n        if self._instrumenter is not None:\n            self._instrumenter.uninstrument()  # otherwise, this gets called in the __del__ method of Tracer\n            self._instrumenter = None\n        self._mcp_servers = []  # drop references to mcp servers so that they get garbage collected\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.agent","title":"<code>agent</code>  <code>property</code>","text":"<p>The underlying agent implementation from the framework.</p> <p>This property is intentionally restricted to maintain framework abstraction and prevent direct dependency on specific agent implementations.</p> <p>If you need functionality that relies on accessing the underlying agent: 1. Consider if the functionality can be added to the AnyAgent interface 2. Submit a GitHub issue describing your use case 3. Contribute a PR implementing the needed functionality</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always raised when this property is accessed</p>"},{"location":"api/agent/#any_agent.AnyAgent.framework","title":"<code>framework</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The Agent Framework used.</p>"},{"location":"api/agent/#any_agent.AnyAgent.create","title":"<code>create(agent_framework, agent_config, managed_agents=None, tracing=None)</code>  <code>classmethod</code>","text":"<p>Create an agent using the given framework and config.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@classmethod\ndef create(\n    cls,\n    agent_framework: AgentFramework | str,\n    agent_config: AgentConfig,\n    managed_agents: list[AgentConfig] | None = None,\n    tracing: TracingConfig | None = None,\n) -&gt; AnyAgent:\n    \"\"\"Create an agent using the given framework and config.\"\"\"\n    return asyncio.get_event_loop().run_until_complete(\n        cls.create_async(\n            agent_framework=agent_framework,\n            agent_config=agent_config,\n            managed_agents=managed_agents,\n            tracing=tracing,\n        )\n    )\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.create_async","title":"<code>create_async(agent_framework, agent_config, managed_agents=None, tracing=None)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Create an agent using the given framework and config.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@classmethod\nasync def create_async(\n    cls,\n    agent_framework: AgentFramework | str,\n    agent_config: AgentConfig,\n    managed_agents: list[AgentConfig] | None = None,\n    tracing: TracingConfig | None = None,\n) -&gt; AnyAgent:\n    \"\"\"Create an agent using the given framework and config.\"\"\"\n    agent_cls = cls._get_agent_type_by_framework(agent_framework)\n    agent = agent_cls(agent_config, managed_agents=managed_agents, tracing=tracing)\n    await agent._load_agent()\n    return agent\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.exit","title":"<code>exit()</code>","text":"<p>Exit the agent and clean up resources.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def exit(self) -&gt; None:\n    \"\"\"Exit the agent and clean up resources.\"\"\"\n    if self._instrumenter is not None:\n        self._instrumenter.uninstrument()  # otherwise, this gets called in the __del__ method of Tracer\n        self._instrumenter = None\n    self._mcp_servers = []  # drop references to mcp servers so that they get garbage collected\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.run","title":"<code>run(prompt, **kwargs)</code>","text":"<p>Run the agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def run(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n    \"\"\"Run the agent with the given prompt.\"\"\"\n    return asyncio.get_event_loop().run_until_complete(\n        self.run_async(prompt, **kwargs)\n    )\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.run_async","title":"<code>run_async(prompt, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run the agent asynchronously with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\nasync def run_async(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n    \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n</code></pre>"},{"location":"api/agent/#any_agent.AnyAgent.serve","title":"<code>serve(serving_config=None)</code>","text":"<p>Serve this agent using the Agent2Agent Protocol (A2A).</p> <p>Parameters:</p> Name Type Description Default <code>serving_config</code> <code>ServingConfig | None</code> <p>See ServingConfig.</p> <code>None</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If the <code>serving</code> dependencies are not installed.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def serve(self, serving_config: ServingConfig | None = None) -&gt; None:\n    \"\"\"Serve this agent using the Agent2Agent Protocol (A2A).\n\n    Args:\n        serving_config: See [ServingConfig][any_agent.config.ServingConfig].\n\n    Raises:\n        ImportError: If the `serving` dependencies are not installed.\n\n    \"\"\"\n    try:\n        from any_agent.serving import _get_a2a_server\n    except ImportError as e:\n        msg = \"You need to `pip install 'git+https://github.com/google/A2A#subdirectory=samples/python' to use this method.\"\n        raise ImportError(msg) from e\n\n    server = _get_a2a_server(self, serving_config=serving_config or ServingConfig())\n    server.start()\n</code></pre>"},{"location":"api/config/","title":"Config","text":""},{"location":"api/config/#any_agent.config.AgentConfig","title":"<code>any_agent.config.AgentConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n\n    model_id: str\n    \"\"\"Select the underlying model used by the agent.\n\n    If you are using the default model_type (LiteLLM), you can refer to [LiteLLM Provider Docs](https://docs.litellm.ai/docs/providers) for the list of providers and how to access them.\n    \"\"\"\n\n    api_base: str | None = None\n    api_key: str | None = None\n\n    description: str | None = None\n    \"\"\"Description of the agent.\"\"\"\n\n    name: str = \"any_agent\"\n    \"\"\"The name of the agent.\n\n    Defaults to `any_agent`.\n    \"\"\"\n\n    instructions: str | None = None\n    \"\"\"Specify the instructions for the agent (often also referred to as a `system_prompt`).\"\"\"\n\n    tools: Sequence[Tool] = Field(default_factory=list)\n    \"\"\"List of tools to be used by the agent.\n\n    See more info at [Tools](../tools.md).\n    \"\"\"\n\n    agent_type: Callable[..., Any] | None = None\n    \"\"\"Control the type of agent class that is used by the framework, and is unique to the framework used.\n\n    Check the individual `Frameworks` pages for more info on the defaults.\n    \"\"\"\n\n    agent_args: MutableMapping[str, Any] | None = None\n    \"\"\"Pass arguments to the instance used by the underlying framework.\n\n    For example, you can pass `output_type` when using the OpenAI Agents SDK:\n\n    ```py\n    from pydantic import BaseModel\n\n    class CalendarEvent(BaseModel):\n        name: str\n        date: str\n        participants: list[str]\n\n    agent = AnyAgent.create(\n        AgentConfig(\n            model_id=\"gpt-4.1-mini\",\n            instructions=\"Extract calendar events from text\",\n            agent_args={\n                \"output_type\": CalendarEvent\n            }\n        )\n    )\n    ```\n    \"\"\"\n\n    model_type: Callable[..., Any] | None = None\n    \"\"\"Control the type of model class that is used by the agent framework, and is unique to the agent framework being used.\n\n    For each framework, we leverage their support for LiteLLM and use it as default model_type, allowing you to use the same model_id syntax across these frameworks.\n    \"\"\"\n\n    model_args: MutableMapping[str, Any] | None = None\n    \"\"\"Pass arguments to the model instance like `temperature`, `top_k`, as well as any other provider-specific parameters.\n\n    Refer to LiteLLM Completion API Docs for more info.\n    \"\"\"\n</code></pre>"},{"location":"api/config/#any_agent.config.AgentConfig.agent_args","title":"<code>agent_args = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Pass arguments to the instance used by the underlying framework.</p> <p>For example, you can pass <code>output_type</code> when using the OpenAI Agents SDK:</p> <pre><code>from pydantic import BaseModel\n\nclass CalendarEvent(BaseModel):\n    name: str\n    date: str\n    participants: list[str]\n\nagent = AnyAgent.create(\n    AgentConfig(\n        model_id=\"gpt-4.1-mini\",\n        instructions=\"Extract calendar events from text\",\n        agent_args={\n            \"output_type\": CalendarEvent\n        }\n    )\n)\n</code></pre>"},{"location":"api/config/#any_agent.config.AgentConfig.agent_type","title":"<code>agent_type = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Control the type of agent class that is used by the framework, and is unique to the framework used.</p> <p>Check the individual <code>Frameworks</code> pages for more info on the defaults.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.description","title":"<code>description = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Description of the agent.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.instructions","title":"<code>instructions = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Specify the instructions for the agent (often also referred to as a <code>system_prompt</code>).</p>"},{"location":"api/config/#any_agent.config.AgentConfig.model_args","title":"<code>model_args = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Pass arguments to the model instance like <code>temperature</code>, <code>top_k</code>, as well as any other provider-specific parameters.</p> <p>Refer to LiteLLM Completion API Docs for more info.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.model_id","title":"<code>model_id</code>  <code>instance-attribute</code>","text":"<p>Select the underlying model used by the agent.</p> <p>If you are using the default model_type (LiteLLM), you can refer to LiteLLM Provider Docs for the list of providers and how to access them.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.model_type","title":"<code>model_type = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Control the type of model class that is used by the agent framework, and is unique to the agent framework being used.</p> <p>For each framework, we leverage their support for LiteLLM and use it as default model_type, allowing you to use the same model_id syntax across these frameworks.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.name","title":"<code>name = 'any_agent'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The name of the agent.</p> <p>Defaults to <code>any_agent</code>.</p>"},{"location":"api/config/#any_agent.config.AgentConfig.tools","title":"<code>tools = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of tools to be used by the agent.</p> <p>See more info at Tools.</p>"},{"location":"api/config/#any_agent.config.TracingConfig","title":"<code>any_agent.config.TracingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class TracingConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n\n    console: bool = True\n    \"\"\"Whether to show traces in the console.\"\"\"\n\n    llm: str | None = \"yellow\"\n    \"\"\"LLM color in console logs\"\"\"\n\n    tool: str | None = \"blue\"\n    \"\"\"Tool color in console logs\"\"\"\n\n    agent: str | None = None\n    \"\"\"Agent color in console logs\"\"\"\n\n    chain: str | None = None\n    \"\"\"Chain color in console logs\"\"\"\n\n    cost_info: bool = True\n    \"\"\"Whether traces should include cost information\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_console_flags(self) -&gt; Self:\n        if self.console and not any([self.llm, self.tool, self.agent, self.chain]):\n            msg = \"At least one of `[self.llm, self.tool, self.agent, self.chain]` must be set\"\n            raise ValueError(msg)\n        return self\n</code></pre>"},{"location":"api/config/#any_agent.config.TracingConfig.agent","title":"<code>agent = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Agent color in console logs</p>"},{"location":"api/config/#any_agent.config.TracingConfig.chain","title":"<code>chain = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chain color in console logs</p>"},{"location":"api/config/#any_agent.config.TracingConfig.console","title":"<code>console = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to show traces in the console.</p>"},{"location":"api/config/#any_agent.config.TracingConfig.cost_info","title":"<code>cost_info = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether traces should include cost information</p>"},{"location":"api/config/#any_agent.config.TracingConfig.llm","title":"<code>llm = 'yellow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>LLM color in console logs</p>"},{"location":"api/config/#any_agent.config.TracingConfig.tool","title":"<code>tool = 'blue'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Tool color in console logs</p>"},{"location":"api/config/#any_agent.config.MCPStdio","title":"<code>any_agent.config.MCPStdio</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPStdio(BaseModel):\n    command: str\n    \"\"\"The executable to run to start the server.\n\n    For example, `docker`, `uvx`, `npx`.\n    \"\"\"\n\n    args: Sequence[str]\n    \"\"\"Command line args to pass to the command executable.\n\n    For example, `[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"]`.\n    \"\"\"\n\n    tools: Sequence[str] | None = None\n    \"\"\"List of tool names to use from the MCP Server.\n\n    Use it to limit the tools accessible by the agent.\n    For example, if you use [`mcp/filesystem`](https://hub.docker.com/r/mcp/filesystem),\n    you can pass `tools=[\"read_file\", \"list_directory\"]` to limit the agent to read-only operations.\n    \"\"\"\n\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True, extra=\"forbid\")\n</code></pre>"},{"location":"api/config/#any_agent.config.MCPStdio.args","title":"<code>args</code>  <code>instance-attribute</code>","text":"<p>Command line args to pass to the command executable.</p> <p>For example, <code>[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"]</code>.</p>"},{"location":"api/config/#any_agent.config.MCPStdio.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/config/#any_agent.config.MCPStdio.command","title":"<code>command</code>  <code>instance-attribute</code>","text":"<p>The executable to run to start the server.</p> <p>For example, <code>docker</code>, <code>uvx</code>, <code>npx</code>.</p>"},{"location":"api/config/#any_agent.config.MCPStdio.tools","title":"<code>tools = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of tool names to use from the MCP Server.</p> <p>Use it to limit the tools accessible by the agent. For example, if you use <code>mcp/filesystem</code>, you can pass <code>tools=[\"read_file\", \"list_directory\"]</code> to limit the agent to read-only operations.</p>"},{"location":"api/config/#any_agent.config.MCPSse","title":"<code>any_agent.config.MCPSse</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPSse(BaseModel):\n    url: str\n    \"\"\"The URL of the server.\"\"\"\n\n    headers: Mapping[str, str] | None = None\n    \"\"\"The headers to send to the server.\"\"\"\n\n    tools: Sequence[str] | None = None\n    \"\"\"List of tool names to use from the MCP Server.\n\n    Use it to limit the tools accessible by the agent.\n    For example, if you use [`mcp/filesystem`](https://hub.docker.com/r/mcp/filesystem),\n    you can pass `tools=[\"read_file\", \"list_directory\"]` to limit the agent to read-only operations.\n    \"\"\"\n\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"api/config/#any_agent.config.MCPSse.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/config/#any_agent.config.MCPSse.headers","title":"<code>headers = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The headers to send to the server.</p>"},{"location":"api/config/#any_agent.config.MCPSse.tools","title":"<code>tools = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>List of tool names to use from the MCP Server.</p> <p>Use it to limit the tools accessible by the agent. For example, if you use <code>mcp/filesystem</code>, you can pass <code>tools=[\"read_file\", \"list_directory\"]</code> to limit the agent to read-only operations.</p>"},{"location":"api/config/#any_agent.config.MCPSse.url","title":"<code>url</code>  <code>instance-attribute</code>","text":"<p>The URL of the server.</p>"},{"location":"api/config/#any_agent.config.ServingConfig","title":"<code>any_agent.config.ServingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for serving an agent using the Agent2Agent Protocol (A2A).</p> <p>We use the example <code>A2ASever</code> from https://github.com/google/A2A/tree/main/samples/python.</p> Source code in <code>src/any_agent/config.py</code> <pre><code>class ServingConfig(BaseModel):\n    \"\"\"Configuration for serving an agent using the Agent2Agent Protocol (A2A).\n\n    We use the example `A2ASever` from https://github.com/google/A2A/tree/main/samples/python.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"forbid\")\n\n    host: str = \"localhost\"\n    \"\"\"Will be passed as argument to `uvicorn.run`.\"\"\"\n\n    port: int = 5000\n    \"\"\"Will be passed as argument to `uvicorn.run`.\"\"\"\n\n    endpoint: str = \"/\"\n    \"\"\"Will be pass as argument to `Starlette().add_route`\"\"\"\n\n    version: str = \"0.1.0\"\n</code></pre>"},{"location":"api/config/#any_agent.config.ServingConfig.endpoint","title":"<code>endpoint = '/'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Will be pass as argument to <code>Starlette().add_route</code></p>"},{"location":"api/config/#any_agent.config.ServingConfig.host","title":"<code>host = 'localhost'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Will be passed as argument to <code>uvicorn.run</code>.</p>"},{"location":"api/config/#any_agent.config.ServingConfig.port","title":"<code>port = 5000</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Will be passed as argument to <code>uvicorn.run</code>.</p>"},{"location":"api/config/#any_agent.config.AgentFramework","title":"<code>any_agent.config.AgentFramework</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentFramework(str, Enum):\n    GOOGLE = auto()\n    LANGCHAIN = auto()\n    LLAMA_INDEX = auto()\n    OPENAI = auto()\n    AGNO = auto()\n    SMOLAGENTS = auto()\n    TINYAGENT = auto()\n\n    @classmethod\n    def from_string(cls, value: str | Self) -&gt; Self:\n        if isinstance(value, cls):\n            return value\n\n        formatted_value = value.strip().upper()\n        if formatted_value not in cls.__members__:\n            error_message = (\n                f\"Unsupported agent framework: '{value}'. \"\n                f\"Valid frameworks are: {list(cls.__members__.keys())}\"\n            )\n            raise ValueError(error_message)\n\n        return cls[formatted_value]\n</code></pre>"},{"location":"api/tools/","title":"Tools","text":""},{"location":"api/tools/#any_agent.tools","title":"<code>any_agent.tools</code>","text":""},{"location":"api/tools/#any_agent.tools.ask_user_verification","title":"<code>ask_user_verification(query)</code>","text":"<p>Asks user to verify the given <code>query</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question that requires verification.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def ask_user_verification(query: str) -&gt; str:\n    \"\"\"Asks user to verify the given `query`.\n\n    Args:\n        query: The question that requires verification.\n\n    \"\"\"\n    return input(f\"{query} =&gt; Type your answer here:\")\n</code></pre>"},{"location":"api/tools/#any_agent.tools.search_web","title":"<code>search_web(query)</code>","text":"<p>Perform a duckduckgo web search based on your query (think a Google search) then returns the top search results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to perform.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The top search results.</p> Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Perform a duckduckgo web search based on your query (think a Google search) then returns the top search results.\n\n    Args:\n        query (str): The search query to perform.\n\n    Returns:\n        The top search results.\n\n    \"\"\"\n    ddgs = DDGS()\n    results = ddgs.text(query, max_results=10)\n    return \"\\n\".join(\n        f\"[{result['title']}]({result['href']})\\n{result['body']}\" for result in results\n    )\n</code></pre>"},{"location":"api/tools/#any_agent.tools.send_console_message","title":"<code>send_console_message(user, query)</code>","text":"<p>Send the specified user a message via console and returns their response.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question to ask the user.</p> required <code>user</code> <code>str</code> <p>The user to ask the question to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's response.</p> Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def send_console_message(user: str, query: str) -&gt; str:\n    \"\"\"Send the specified user a message via console and returns their response.\n\n    Args:\n        query: The question to ask the user.\n        user: The user to ask the question to.\n\n    Returns:\n        str: The user's response.\n\n    \"\"\"\n    return Prompt.ask(f\"{query}\\n{user}\")\n</code></pre>"},{"location":"api/tools/#any_agent.tools.show_final_output","title":"<code>show_final_output(answer)</code>","text":"<p>Show the final answer to the user.</p> <p>Parameters:</p> Name Type Description Default <code>answer</code> <code>str</code> <p>The final answer.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_final_output(answer: str) -&gt; str:\n    \"\"\"Show the final answer to the user.\n\n    Args:\n        answer: The final answer.\n\n    \"\"\"\n    logger.info(f\"Final output: {answer}\")\n    return answer\n</code></pre>"},{"location":"api/tools/#any_agent.tools.show_plan","title":"<code>show_plan(plan)</code>","text":"<p>Show the current plan to the user.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>str</code> <p>The current plan.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_plan(plan: str) -&gt; str:\n    \"\"\"Show the current plan to the user.\n\n    Args:\n        plan: The current plan.\n\n    \"\"\"\n    logger.info(f\"Current plan: {plan}\")\n    return plan\n</code></pre>"},{"location":"api/tools/#any_agent.tools.visit_webpage","title":"<code>visit_webpage(url)</code>","text":"<p>Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the webpage to visit.</p> required Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def visit_webpage(url: str) -&gt; str:\n    \"\"\"Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.\n\n    Args:\n        url: The url of the webpage to visit.\n\n    \"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n\n        markdown_content = markdownify(response.text).strip()  # type: ignore[no-untyped-call]\n\n        markdown_content = re.sub(r\"\\n{2,}\", \"\\n\", markdown_content)\n\n        return _truncate_content(markdown_content, 10000)\n    except RequestException as e:\n        return f\"Error fetching the webpage: {e!s}\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {e!s}\"\n</code></pre>"},{"location":"api/tracing/","title":"Tracing","text":""},{"location":"api/tracing/#any_agent.tracing.trace.AgentTrace","title":"<code>any_agent.tracing.trace.AgentTrace</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A trace that can be exported to JSON or printed to the console.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>class AgentTrace(BaseModel):\n    \"\"\"A trace that can be exported to JSON or printed to the console.\"\"\"\n\n    spans: list[AgentSpan] = Field(default_factory=list)\n    \"\"\"A list of [`AgentSpan`][any_agent.tracing.trace.AgentSpan] that form the trace.\n    \"\"\"\n\n    final_output: str | None = None\n    \"\"\"Contains the final output message returned by the agent.\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def get_total_cost(self) -&gt; TotalTokenUseAndCost:\n        \"\"\"Return the current total cost and token usage statistics.\"\"\"\n        counts: list[CountInfo] = []\n        costs: list[CostInfo] = []\n        for span in self.spans:\n            if span.attributes and \"cost_prompt\" in span.attributes:\n                count = CountInfo(\n                    token_count_prompt=span.attributes[\"llm.token_count.prompt\"],\n                    token_count_completion=span.attributes[\n                        \"llm.token_count.completion\"\n                    ],\n                )\n                cost = CostInfo(\n                    cost_prompt=span.attributes[\"cost_prompt\"],\n                    cost_completion=span.attributes[\"cost_completion\"],\n                )\n                counts.append(count)\n                costs.append(cost)\n\n        total_cost = sum(cost.cost_prompt + cost.cost_completion for cost in costs)\n        total_tokens = sum(\n            count.token_count_prompt + count.token_count_completion for count in counts\n        )\n        total_token_count_prompt = sum(count.token_count_prompt for count in counts)\n        total_token_count_completion = sum(\n            count.token_count_completion for count in counts\n        )\n        total_cost_prompt = sum(cost.cost_prompt for cost in costs)\n        total_cost_completion = sum(cost.cost_completion for cost in costs)\n        return TotalTokenUseAndCost(\n            total_cost=total_cost,\n            total_tokens=total_tokens,\n            total_token_count_prompt=total_token_count_prompt,\n            total_token_count_completion=total_token_count_completion,\n            total_cost_prompt=total_cost_prompt,\n            total_cost_completion=total_cost_completion,\n        )\n</code></pre>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentTrace.final_output","title":"<code>final_output = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Contains the final output message returned by the agent.</p>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentTrace.spans","title":"<code>spans = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>A list of <code>AgentSpan</code> that form the trace.</p>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentTrace.get_total_cost","title":"<code>get_total_cost()</code>","text":"<p>Return the current total cost and token usage statistics.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>def get_total_cost(self) -&gt; TotalTokenUseAndCost:\n    \"\"\"Return the current total cost and token usage statistics.\"\"\"\n    counts: list[CountInfo] = []\n    costs: list[CostInfo] = []\n    for span in self.spans:\n        if span.attributes and \"cost_prompt\" in span.attributes:\n            count = CountInfo(\n                token_count_prompt=span.attributes[\"llm.token_count.prompt\"],\n                token_count_completion=span.attributes[\n                    \"llm.token_count.completion\"\n                ],\n            )\n            cost = CostInfo(\n                cost_prompt=span.attributes[\"cost_prompt\"],\n                cost_completion=span.attributes[\"cost_completion\"],\n            )\n            counts.append(count)\n            costs.append(cost)\n\n    total_cost = sum(cost.cost_prompt + cost.cost_completion for cost in costs)\n    total_tokens = sum(\n        count.token_count_prompt + count.token_count_completion for count in counts\n    )\n    total_token_count_prompt = sum(count.token_count_prompt for count in counts)\n    total_token_count_completion = sum(\n        count.token_count_completion for count in counts\n    )\n    total_cost_prompt = sum(cost.cost_prompt for cost in costs)\n    total_cost_completion = sum(cost.cost_completion for cost in costs)\n    return TotalTokenUseAndCost(\n        total_cost=total_cost,\n        total_tokens=total_tokens,\n        total_token_count_prompt=total_token_count_prompt,\n        total_token_count_completion=total_token_count_completion,\n        total_cost_prompt=total_cost_prompt,\n        total_cost_completion=total_cost_completion,\n    )\n</code></pre>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentSpan","title":"<code>any_agent.tracing.trace.AgentSpan</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A span that can be exported to JSON or printed to the console.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>class AgentSpan(BaseModel):\n    \"\"\"A span that can be exported to JSON or printed to the console.\"\"\"\n\n    name: str\n    kind: SpanKind\n    parent: SpanContext | None = None\n    start_time: int | None = None\n    end_time: int | None = None\n    status: Status\n    context: SpanContext\n    attributes: dict[str, Any]\n    links: list[Link]\n    events: list[Event]\n    resource: Resource\n\n    model_config = ConfigDict(arbitrary_types_allowed=False)\n\n    @classmethod\n    def from_readable_span(cls, readable_span: \"ReadableSpan\") -&gt; \"AgentSpan\":\n        \"\"\"Create an AgentSpan from a ReadableSpan.\"\"\"\n        return cls(\n            name=readable_span.name,\n            kind=SpanKind.from_otel(readable_span.kind),\n            parent=SpanContext.from_otel(readable_span.parent),\n            start_time=readable_span.start_time,\n            end_time=readable_span.end_time,\n            status=Status.from_otel(readable_span.status),\n            context=SpanContext.from_otel(readable_span.context),\n            attributes=dict(readable_span.attributes)\n            if readable_span.attributes\n            else {},\n            links=[Link.from_otel(link) for link in readable_span.links],\n            events=[Event.from_otel(event) for event in readable_span.events],\n            resource=Resource.from_otel(readable_span.resource),\n        )\n\n    def add_cost_info(self) -&gt; None:\n        \"\"\"Extend attributes with `TokenUseAndCost`.\"\"\"\n        cost_info = extract_token_use_and_cost(self.attributes)\n        if cost_info:\n            self.set_attributes(cost_info.model_dump(exclude_none=True))\n\n    def set_attributes(self, attributes: Mapping[str, AttributeValue]) -&gt; None:\n        \"\"\"Set attributes for the span.\"\"\"\n        for key, value in attributes.items():\n            if key in self.attributes:\n                logger.warning(\"Overwriting attribute %s with %s\", key, value)\n            self.attributes[key] = value\n</code></pre>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentSpan.add_cost_info","title":"<code>add_cost_info()</code>","text":"<p>Extend attributes with <code>TokenUseAndCost</code>.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>def add_cost_info(self) -&gt; None:\n    \"\"\"Extend attributes with `TokenUseAndCost`.\"\"\"\n    cost_info = extract_token_use_and_cost(self.attributes)\n    if cost_info:\n        self.set_attributes(cost_info.model_dump(exclude_none=True))\n</code></pre>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentSpan.from_readable_span","title":"<code>from_readable_span(readable_span)</code>  <code>classmethod</code>","text":"<p>Create an AgentSpan from a ReadableSpan.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>@classmethod\ndef from_readable_span(cls, readable_span: \"ReadableSpan\") -&gt; \"AgentSpan\":\n    \"\"\"Create an AgentSpan from a ReadableSpan.\"\"\"\n    return cls(\n        name=readable_span.name,\n        kind=SpanKind.from_otel(readable_span.kind),\n        parent=SpanContext.from_otel(readable_span.parent),\n        start_time=readable_span.start_time,\n        end_time=readable_span.end_time,\n        status=Status.from_otel(readable_span.status),\n        context=SpanContext.from_otel(readable_span.context),\n        attributes=dict(readable_span.attributes)\n        if readable_span.attributes\n        else {},\n        links=[Link.from_otel(link) for link in readable_span.links],\n        events=[Event.from_otel(event) for event in readable_span.events],\n        resource=Resource.from_otel(readable_span.resource),\n    )\n</code></pre>"},{"location":"api/tracing/#any_agent.tracing.trace.AgentSpan.set_attributes","title":"<code>set_attributes(attributes)</code>","text":"<p>Set attributes for the span.</p> Source code in <code>src/any_agent/tracing/trace.py</code> <pre><code>def set_attributes(self, attributes: Mapping[str, AttributeValue]) -&gt; None:\n    \"\"\"Set attributes for the span.\"\"\"\n    for key, value in attributes.items():\n        if key in self.attributes:\n            logger.warning(\"Overwriting attribute %s with %s\", key, value)\n        self.attributes[key] = value\n</code></pre>"},{"location":"frameworks/agno/","title":"Agno","text":"<p>https://github.com/agno-agi/agno</p>"},{"location":"frameworks/agno/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>agno.agent.Agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/agno/#default-model-type","title":"Default Model Type","text":"<p>We use <code>agno.models.litellm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/agno/#examples","title":"Examples","text":""},{"location":"frameworks/agno/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"agno\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    ),\n    agent_args={\n        \"tool_call_limit\": 3\n    }\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"frameworks/google_adk/","title":"Google Agent Development Kit (ADK)","text":"<p>https://github.com/google/adk-python</p>"},{"location":"frameworks/google_adk/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>google.adk.agents.llm_agent.LlmAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/google_adk/#default-model-type","title":"Default Model Type","text":"<p>We use <code>google.adk.models.lite_llm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/google_adk/#run-args","title":"Run args","text":"<p>Check <code>RunConfig</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/google_adk/#examples","title":"Examples","text":""},{"location":"frameworks/google_adk/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\nfrom google.adk.agents.run_config import RunConfig\n\nagent = AnyAgent.create(\n    \"google\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    run_config=RunConfig(\n        max_llm_calls=3\n    )\n)\n</code></pre>"},{"location":"frameworks/google_adk/#using-handoff","title":"Using <code>handoff</code>","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, show_final_output, visit_webpage\n\nmain_agent = AgentConfig(\n    model_id=\"o3-mini\",\n)\n\nmanaged_agents = [\n    AgentConfig(\n        model_id=\"gpt-4o\",\n        name=\"search-web-agent\",\n        tools=[\n            search_web,\n            visit_webpage,\n        ],\n    ),\n    AgentConfig(\n        model_id=\"gpt-4o-mini\",\n        name=\"communication-agent\",\n        tools=[show_final_output],\n        agent_args={\n            \"handoff\": True\n        }\n    ),\n]\n\nAnyAgent.create(\n    \"google\",\n    main_agent,\n    managed_agents=managed_agents,\n)\n</code></pre>"},{"location":"frameworks/langchain/","title":"LangChain","text":"<p>https://github.com/langchain-ai/langchain</p> <p>https://github.com/langchain-ai/langgraph</p>"},{"location":"frameworks/langchain/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>langgraph.prebuilt.create_react_agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/langchain/#default-model-type","title":"Default Model Type","text":"<p>We use <code>langchain_litellm.ChatLiteLLM</code> Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/langchain/#run-args","title":"Run args","text":"<p>Check <code>RunnableConfig</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/langchain/#examples","title":"Examples","text":""},{"location":"frameworks/langchain/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\nfrom langchain_core.runnables import RunnableConfig\n\nagent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    config=RunnableConfig(\n        recursion_limit=3\n    )\n)\n</code></pre>"},{"location":"frameworks/llama_index/","title":"LlamaIndex","text":"<p>https://github.com/run-llama/llama_index</p>"},{"location":"frameworks/llama_index/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>llama_index.core.agent.workflow.react_agent.ReActAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/llama_index/#default-model-type","title":"Default Model Type","text":"<p>We use <code>llama_index.llms.litellm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/llama_index/#examples","title":"Examples","text":""},{"location":"frameworks/llama_index/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<p>Pending on https://github.com/run-llama/llama_index/issues/18535</p>"},{"location":"frameworks/openai/","title":"OpenAI Agents SDK","text":"<p>https://github.com/openai/openai-agents-python</p>"},{"location":"frameworks/openai/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>agents.Agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/openai/#default-model-type","title":"Default Model Type","text":"<p>We use <code>agents.extensions.models.litellm_model.LitellmModel</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/openai/#run-args","title":"Run args","text":"<p>Check <code>agents.run.Runner.run</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/openai/#examples","title":"Examples","text":""},{"location":"frameworks/openai/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    max_turns=3\n)\n</code></pre>"},{"location":"frameworks/openai/#using-handoff","title":"Using <code>handoff</code>","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, show_final_output, visit_webpage\n\nmain_agent = AgentConfig(\n    model_id=\"o3-mini\",\n)\n\nmanaged_agents = [\n    AgentConfig(\n        model_id=\"gpt-4o\",\n        name=\"search-web-agent\",\n        tools=[\n            search_web,\n            visit_webpage,\n        ],\n    ),\n    AgentConfig(\n        model_id=\"gpt-4o-mini\",\n        name=\"communication-agent\",\n        tools=[show_final_output],\n        agent_args={\n            \"handoff\": True\n        }\n    ),\n]\n\nAnyAgent.create(\n    \"openai\",\n    main_agent,\n    managed_agents=managed_agents,\n)\n</code></pre>"},{"location":"frameworks/smolagents/","title":"smolagents","text":"<p>https://github.com/huggingface/smolagents</p>"},{"location":"frameworks/smolagents/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>smolagents.CodeAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/smolagents/#default-model-type","title":"Default Model Type","text":"<p>We use <code>smolagents.LiteLLMModel</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/smolagents/#run-args","title":"Run args","text":"<p>Check <code>smolagents.MultiStepAgent.run</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/smolagents/#examples","title":"Examples","text":""},{"location":"frameworks/smolagents/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"smolagents\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    max_steps=3\n)\n</code></pre>"},{"location":"frameworks/tinyagent/","title":"TinyAgent","text":"<p>As part of the bare bones library, we provide our own Python implementation based on HuggingFace Tiny Agents.</p> <p>You can find it in <code>any_agent.frameworks.tinyagent</code>.</p>"},{"location":"frameworks/tinyagent/#examples","title":"Examples","text":""},{"location":"frameworks/tinyagent/#use-mcp-tools","title":"Use MCP Tools","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.config import MCPStdio\n\nagent = AnyAgent.create(\n    \"tinyagent\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[\n            MCPStdio(\n                command=\"uvx\",\n                args=[\"duckduckgo-mcp-server\"]\n            )\n        ]\n    )\n)\n\nresult = agent.run(\n    \"Which Agent Framework is the best??\"\n)\nprint(result.final_output)\n</code></pre>"}]}