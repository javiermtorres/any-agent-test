{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"any-agent","text":"<p><code>any-agent</code> is a Python library providing a single interface to different agent frameworks.</p> <p>Warning</p> <p>Compared to traditional code-defined workflows, agent frameworks introduce complexity, additional security implications to consider, and demand much more computational power.</p> <p>Before jumping to use one, carefully consider and evaluate how much value you would get compared to manually defining a sequence of tools and LLM calls.</p>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>You can install the bare bones library as follows (only <code>TinyAgent</code> will be available):</p> <pre><code>pip install any-agent\n</code></pre> <p>Or you can install it with the required dependencies for one of more frameworks:</p> <pre><code>pip install any-agent[agno,openai]\n</code></pre> <p>Refer to pyproject.toml for a list of the options available.</p>"},{"location":"agents/","title":"Agents","text":""},{"location":"agents/#defining-agents","title":"Defining Agents","text":"<p>To define any agent system you will always use the same imports:</p> <pre><code>from any_agent import AgentConfig, AnyAgent\n# In these examples, the built-in tools will be used\nfrom any_agent.tools import search_web, visit_webpage\n</code></pre>"},{"location":"agents/#model-id","title":"Model ID","text":"<p><code>model_id</code> allows to select the underlying model used by the agent. If you are using the default <code>model_type</code> (LiteLLM), you can refer to LiteLLM Provider Docs for the list of providers and how to access them.</p> <p>Note</p> <p>If you plan on using a model that requires access to an external service (e.g. OpenAI, Mistral, DeepSeek, etc), you'll need to set any relevant environment variables, e.g.</p> <pre><code>export OPENAI_API_KEY=your_api_key_here\nexport DEEPSEEK_API_KEY=your_api_key_here\n</code></pre>"},{"location":"agents/#single-agent","title":"Single Agent","text":"<pre><code>agent = AnyAgent.create(\n    \"openai\",  # See other options under `Frameworks`\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"Use the tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    ),\n)\n</code></pre>"},{"location":"agents/#multi-agent","title":"Multi-Agent","text":"<p>Warning</p> <p>A multi-agent system introduces even more complexity than a single agent.</p> <p>As stated before, carefully consider whether you need to adopt this pattern to solve the task.</p> <pre><code>agent = AnyAgent.create(\n    \"openai\",  # See other options under `Frameworks`\n    AgentConfig(\n        model_id=\"gpt-4.1-mini\",\n        instructions=\"You are the main agent. Use the other available agents to find an answer\",\n    ),\n    managed_agents=[\n        AgentConfig(\n            name=\"search_web_agent\",\n            description=\"An agent that can search the web\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[search_web]\n        ),\n        AgentConfig(\n            name=\"visit_webpage_agent\",\n            description=\"An agent that can visit webpages\",\n            model_id=\"gpt-4.1-nano\",\n            tools=[visit_webpage]\n        )\n    ]\n)\n</code></pre>"},{"location":"agents/#running-agents","title":"Running Agents","text":"<p>Regardless of the definition (single-agent or multi-agent), you can run the agent as follows:</p> <pre><code>agent_trace = agent.run(\"Which Agent Framework is the best??\")\nprint(agent_trace.final_output)\n</code></pre>"},{"location":"agents/#async","title":"Async","text":"<p>If you are running in <code>async</code> context, you should use the equivalent <code>create_async</code> and <code>run_async</code> methods:</p> <pre><code>import asyncio\n\nasync def main():\n    agent = await AnyAgent.create_async(\n        \"openai\",\n        AgentConfig(\n            model_id=\"gpt-4.1-mini\",\n            instructions=\"You are the main agent. Use the other available agents to find an answer\",\n        ),\n        managed_agents=[\n            AgentConfig(\n                name=\"search_web_agent\",\n                description=\"An agent that can search the web\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[search_web]\n            ),\n            AgentConfig(\n                name=\"visit_webpage_agent\",\n                description=\"An agent that can visit webpages\",\n                model_id=\"gpt-4.1-nano\",\n                tools=[visit_webpage]\n            )\n        ]\n    )\n\n    agent_trace = await agent.run_async(\"Which Agent Framework is the best??\")\n    print(agent_trace.final_output)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"agents/#advanced-configuration","title":"Advanced configuration","text":"<p>Tip</p> <p>Check the <code>Frameworks</code> pages for more details on each of these configuration options.</p>"},{"location":"agents/#agent-args","title":"Agent Args","text":"<p><code>agent_args</code> are passed when creating the instance used by the underlying framework.</p> <p>For example, you can pass <code>output_type</code> when using the OpenAI Agents SDK:</p> <pre><code>from pydantic import BaseModel\n\nclass CalendarEvent(BaseModel):\n    name: str\n    date: str\n    participants: list[str]\n\nagent = AnyAgent.create(\n    AgentConfig(\n        model_id=\"gpt-4.1-mini\",\n        instructions=\"Extract calendar events from text\",\n        agent_args={\n            \"output_type\": CalendarEvent\n        }\n    )\n)\n</code></pre>"},{"location":"agents/#agent-type","title":"Agent Type","text":"<p><code>agent_type</code> controls the type of agent class that is used by the framework, and is unique to the framework used.</p> <p>Check the individual <code>Frameworks</code> pages for more info on the defaults.</p>"},{"location":"agents/#model-args","title":"Model Args","text":"<p><code>model_args</code> allows to set parameters like <code>temperature</code>, <code>top_k</code>, as well as any other provider-specific parameters. Refer to LiteLLM Completion API Docs for more info.</p>"},{"location":"agents/#model-type","title":"Model Type","text":"<p><code>model_type</code> controls the type of model class that is used by the agent framework, and is unique to the agent framework being used.</p> <p>For each framework, we leverage their support for <code>LiteLLM</code> and use it as default <code>model_type</code>, allowing you to use the same <code>model_id</code> syntax across these frameworks.</p>"},{"location":"agents/#run-args","title":"Run Args","text":"<p>You can pass arbitrary <code>key=value</code> arguments to <code>agent.run</code> and they will be forwarded to the corresponding method used by the underlying framework.</p> <p>For example you can pass <code>max_turns=30</code> when using the OpenAI Agents SDK:</p> <pre><code>agent.run(\"Which agent framework is the best?\", max_turns=30)\n</code></pre>"},{"location":"agents/#cleaning-up-the-agent","title":"Cleaning up the Agent","text":"<p>When an AnyAgent object is deleted, the python garbage collector cleans up any resources owned by the object. However, when running or re-creating an agent in the same python process (for example, in test scripts) it may be necessary to forcefully shut down the agent to avoid unexpected side affects. For this purpose, <code>agent.exit</code> is available which will shut down all resources the agent was using.</p> <p>For example,</p> <pre><code>agent.run(\"Which agent framework is the best?\")\nagent.exit() # cleans up the agent synchronously\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#any_agent.AnyAgent","title":"<code>any_agent.AnyAgent</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base abstract class for all agent implementations.</p> <p>This provides a unified interface for different agent frameworks.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>class AnyAgent(ABC):\n    \"\"\"Base abstract class for all agent implementations.\n\n    This provides a unified interface for different agent frameworks.\n    \"\"\"\n\n    def __init__(\n        self,\n        config: AgentConfig,\n        managed_agents: Sequence[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ):\n        self.config = config\n        self.managed_agents = managed_agents\n\n        self._mcp_servers: list[MCPServerBase] = []\n\n        # Tracing is enabled by default\n        self._tracing_config: TracingConfig = tracing or TracingConfig()\n        self._setup_tracing()\n\n    @staticmethod\n    def _get_agent_type_by_framework(\n        framework_raw: AgentFramework | str,\n    ) -&gt; type[AnyAgent]:\n        framework = AgentFramework.from_string(framework_raw)\n\n        if framework is AgentFramework.SMOLAGENTS:\n            from any_agent.frameworks.smolagents import SmolagentsAgent\n\n            return SmolagentsAgent\n\n        if framework is AgentFramework.LANGCHAIN:\n            from any_agent.frameworks.langchain import LangchainAgent\n\n            return LangchainAgent\n\n        if framework is AgentFramework.OPENAI:\n            from any_agent.frameworks.openai import OpenAIAgent\n\n            return OpenAIAgent\n\n        if framework is AgentFramework.LLAMA_INDEX:\n            from any_agent.frameworks.llama_index import LlamaIndexAgent\n\n            return LlamaIndexAgent\n\n        if framework is AgentFramework.GOOGLE:\n            from any_agent.frameworks.google import GoogleAgent\n\n            return GoogleAgent\n\n        if framework is AgentFramework.AGNO:\n            from any_agent.frameworks.agno import AgnoAgent\n\n            return AgnoAgent\n\n        if framework is AgentFramework.TINYAGENT:\n            from any_agent.frameworks.tinyagent import TinyAgent\n\n            return TinyAgent\n\n        assert_never(framework)\n\n    @classmethod\n    def create(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        return asyncio.get_event_loop().run_until_complete(\n            cls.create_async(\n                agent_framework=agent_framework,\n                agent_config=agent_config,\n                managed_agents=managed_agents,\n                tracing=tracing,\n            )\n        )\n\n    @classmethod\n    async def create_async(\n        cls,\n        agent_framework: AgentFramework | str,\n        agent_config: AgentConfig,\n        managed_agents: list[AgentConfig] | None = None,\n        tracing: TracingConfig | None = None,\n    ) -&gt; AnyAgent:\n        agent_cls = cls._get_agent_type_by_framework(agent_framework)\n        agent = agent_cls(agent_config, managed_agents=managed_agents, tracing=tracing)\n        await agent.load_agent()\n        return agent\n\n    async def _load_tools(\n        self, tools: Sequence[Tool]\n    ) -&gt; tuple[list[Any], list[MCPServerBase]]:\n        tools, mcp_servers = await _wrap_tools(tools, self.framework)\n        # Add to agent so that it doesn't get garbage collected\n        self._mcp_servers.extend(mcp_servers)\n        for mcp_server in mcp_servers:\n            tools.extend(mcp_server.tools)\n        return tools, mcp_servers\n\n    def _setup_tracing(self) -&gt; None:\n        \"\"\"Initialize the tracing for the agent.\"\"\"\n        tracer_provider = TracerProvider()\n\n        self._exporter = AnyAgentExporter(self.framework, self._tracing_config)\n\n        # Agno not yet supported https://github.com/Arize-ai/openinference/issues/1302\n        # Google ADK not yet supported https://github.com/Arize-ai/openinference/issues/1506\n        if not is_tracing_supported(self.framework):\n            logger.warning(\n                \"Tracing is not yet supported for AGNO and GOOGLE frameworks. \"\n            )\n            self._instrumenter = None\n            return\n\n        tracer_provider.add_span_processor(SimpleSpanProcessor(self._exporter))\n\n        trace.set_tracer_provider(tracer_provider)\n\n        self._instrumenter = get_instrumenter_by_framework(self.framework)\n        self._instrumenter.instrument(tracer_provider=tracer_provider)\n\n    def run(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n        \"\"\"Run the agent with the given prompt.\"\"\"\n        return asyncio.get_event_loop().run_until_complete(\n            self.run_async(prompt, **kwargs)\n        )\n\n    @abstractmethod\n    async def load_agent(self) -&gt; None:\n        \"\"\"Load the agent instance.\"\"\"\n\n    @abstractmethod\n    async def run_async(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n        \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n\n    @property\n    @abstractmethod\n    def framework(self) -&gt; AgentFramework:\n        \"\"\"The Agent Framework used.\"\"\"\n\n    @property\n    def agent(self) -&gt; Any:\n        \"\"\"The underlying agent implementation from the framework.\n\n        This property is intentionally restricted to maintain framework abstraction\n        and prevent direct dependency on specific agent implementations.\n\n        If you need functionality that relies on accessing the underlying agent:\n        1. Consider if the functionality can be added to the AnyAgent interface\n        2. Submit a GitHub issue describing your use case\n        3. Contribute a PR implementing the needed functionality\n\n        Raises:\n            NotImplementedError: Always raised when this property is accessed\n\n        \"\"\"\n        msg = \"Cannot access the 'agent' property of AnyAgent, if you need to use functionality that relies on the underlying agent framework, please file a Github Issue or we welcome a PR to add the functionality to the AnyAgent class\"\n        raise NotImplementedError(msg)\n\n    def exit(self) -&gt; None:\n        \"\"\"Exit the agent and clean up resources.\"\"\"\n        if self._instrumenter is not None:\n            self._instrumenter.uninstrument()  # otherwise, this gets called in the __del__ method of Tracer\n            self._instrumenter = None\n        self._mcp_servers = []  # drop references to mcp servers so that they get garbage collected\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.agent","title":"<code>agent</code>  <code>property</code>","text":"<p>The underlying agent implementation from the framework.</p> <p>This property is intentionally restricted to maintain framework abstraction and prevent direct dependency on specific agent implementations.</p> <p>If you need functionality that relies on accessing the underlying agent: 1. Consider if the functionality can be added to the AnyAgent interface 2. Submit a GitHub issue describing your use case 3. Contribute a PR implementing the needed functionality</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Always raised when this property is accessed</p>"},{"location":"api/#any_agent.AnyAgent.framework","title":"<code>framework</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>The Agent Framework used.</p>"},{"location":"api/#any_agent.AnyAgent.exit","title":"<code>exit()</code>","text":"<p>Exit the agent and clean up resources.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def exit(self) -&gt; None:\n    \"\"\"Exit the agent and clean up resources.\"\"\"\n    if self._instrumenter is not None:\n        self._instrumenter.uninstrument()  # otherwise, this gets called in the __del__ method of Tracer\n        self._instrumenter = None\n    self._mcp_servers = []  # drop references to mcp servers so that they get garbage collected\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.load_agent","title":"<code>load_agent()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Load the agent instance.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\nasync def load_agent(self) -&gt; None:\n    \"\"\"Load the agent instance.\"\"\"\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.run","title":"<code>run(prompt, **kwargs)</code>","text":"<p>Run the agent with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>def run(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n    \"\"\"Run the agent with the given prompt.\"\"\"\n    return asyncio.get_event_loop().run_until_complete(\n        self.run_async(prompt, **kwargs)\n    )\n</code></pre>"},{"location":"api/#any_agent.AnyAgent.run_async","title":"<code>run_async(prompt, **kwargs)</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>Run the agent asynchronously with the given prompt.</p> Source code in <code>src/any_agent/frameworks/any_agent.py</code> <pre><code>@abstractmethod\nasync def run_async(self, prompt: str, **kwargs: Any) -&gt; AgentTrace:\n    \"\"\"Run the agent asynchronously with the given prompt.\"\"\"\n</code></pre>"},{"location":"api/#any_agent.AgentFramework","title":"<code>any_agent.AgentFramework</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentFramework(str, Enum):\n    GOOGLE = auto()\n    LANGCHAIN = auto()\n    LLAMA_INDEX = auto()\n    OPENAI = auto()\n    AGNO = auto()\n    SMOLAGENTS = auto()\n    TINYAGENT = auto()\n\n    @classmethod\n    def from_string(cls, value: str | Self) -&gt; Self:\n        if isinstance(value, cls):\n            return value\n\n        formatted_value = value.strip().upper()\n        if formatted_value not in cls.__members__:\n            error_message = (\n                f\"Unsupported agent framework: '{value}'. \"\n                f\"Valid frameworks are: {list(cls.__members__.keys())}\"\n            )\n            raise ValueError(error_message)\n\n        return cls[formatted_value]\n</code></pre>"},{"location":"api/#any_agent.AgentConfig","title":"<code>any_agent.AgentConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class AgentConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n    model_id: str\n    api_base: str | None = None\n    api_key: str | None = None\n    description: str | None = None\n    name: str = \"any_agent\"\n    instructions: str | None = None\n    tools: Sequence[Tool] = Field(default_factory=list)\n    handoff: bool = False\n    agent_type: Callable[..., Any] | None = None\n    agent_args: MutableMapping[str, Any] | None = None\n    model_type: Callable[..., Any] | None = None\n    model_args: MutableMapping[str, Any] | None = None\n</code></pre>"},{"location":"api/#any_agent.config.MCPStdioParams","title":"<code>any_agent.config.MCPStdioParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPStdioParams(BaseModel):\n    command: str\n    args: Sequence[str]\n    tools: Sequence[str] | None = None\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True, extra=\"forbid\")\n</code></pre>"},{"location":"api/#any_agent.config.MCPStdioParams.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/#any_agent.config.MCPSseParams","title":"<code>any_agent.config.MCPSseParams</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class MCPSseParams(BaseModel):\n    url: str\n    headers: Mapping[str, str] | None = None\n    tools: Sequence[str] | None = None\n    client_session_timeout_seconds: float | None = 5\n    \"\"\"the read timeout passed to the MCP ClientSession.\"\"\"\n\n    model_config = ConfigDict(frozen=True)\n</code></pre>"},{"location":"api/#any_agent.config.MCPSseParams.client_session_timeout_seconds","title":"<code>client_session_timeout_seconds = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>the read timeout passed to the MCP ClientSession.</p>"},{"location":"api/#any_agent.config.TracingConfig","title":"<code>any_agent.config.TracingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>src/any_agent/config.py</code> <pre><code>class TracingConfig(BaseModel):\n    model_config = ConfigDict(extra=\"forbid\")\n\n    console: bool = True\n    \"\"\"Print to console.\"\"\"\n\n    output_dir: str = \"traces\"\n    \"\"\"Directory to save traces, if json is enabled\"\"\"\n\n    save: bool = True\n    \"\"\"Save to json file.\"\"\"\n\n    cost_info: bool = True\n    \"\"\"whether json and console logs should include cost information\"\"\"\n\n    llm: str | None = \"yellow\"\n    \"\"\"LLM color in console logs\"\"\"\n\n    tool: str | None = \"blue\"\n    \"\"\"Tool color in console logs\"\"\"\n\n    agent: str | None = None\n    \"\"\"Agent color in console logs\"\"\"\n\n    chain: str | None = None\n    \"\"\"Chain color in console logs\"\"\"\n\n    @model_validator(mode=\"after\")\n    def validate_output_dir(self) -&gt; Self:\n        if self.save and not self.output_dir:\n            msg = \"output_dir must be set if `save` is enabled\"\n            raise ValueError(msg)\n        return self\n</code></pre>"},{"location":"api/#any_agent.config.TracingConfig.agent","title":"<code>agent = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Agent color in console logs</p>"},{"location":"api/#any_agent.config.TracingConfig.chain","title":"<code>chain = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Chain color in console logs</p>"},{"location":"api/#any_agent.config.TracingConfig.console","title":"<code>console = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Print to console.</p>"},{"location":"api/#any_agent.config.TracingConfig.cost_info","title":"<code>cost_info = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>whether json and console logs should include cost information</p>"},{"location":"api/#any_agent.config.TracingConfig.llm","title":"<code>llm = 'yellow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>LLM color in console logs</p>"},{"location":"api/#any_agent.config.TracingConfig.output_dir","title":"<code>output_dir = 'traces'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Directory to save traces, if json is enabled</p>"},{"location":"api/#any_agent.config.TracingConfig.save","title":"<code>save = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Save to json file.</p>"},{"location":"api/#any_agent.config.TracingConfig.tool","title":"<code>tool = 'blue'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Tool color in console logs</p>"},{"location":"api/#any_agent.tools","title":"<code>any_agent.tools</code>","text":""},{"location":"api/#any_agent.tools.MCPConnection","title":"<code>MCPConnection</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> Source code in <code>src/any_agent/tools/mcp/mcp_connection.py</code> <pre><code>class MCPConnection(BaseModel, ABC):\n    mcp_tool: MCPParams\n    _exit_stack: AsyncExitStack = PrivateAttr(default_factory=AsyncExitStack)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    @abstractmethod\n    async def list_tools(self) -&gt; list[Tool]:\n        \"\"\"List tools from the MCP server.\"\"\"\n\n    @property\n    def server(self) -&gt; \"MCPServer | None\":\n        \"\"\"Return the MCP server instance.\"\"\"\n        return None\n\n    def _filter_tools(self, tools: ToolsWithName) -&gt; ToolsWithName:\n        # Only add the tools listed in mcp_tool['tools'] if specified\n        requested_tools = list(self.mcp_tool.tools or [])\n\n        if not requested_tools:\n            return tools\n\n        tool_names = [\n            tool.name if isinstance(tool, HasName) else tool for tool in tools\n        ]\n\n        found_tools = [tool for tool in tool_names if tool in requested_tools]\n\n        if len(found_tools) != len(requested_tools):\n            error_message = (\n                dedent(\n                    f\"\"\"Could not find all requested tools in the MCP server:\n                    Requested ({len(requested_tools)}): {requested_tools}\n                    Set ({len(tool_names)}):   {tool_names}\n                \"\"\"\n                ),\n            )\n            raise ValueError(error_message)\n        return tools\n</code></pre>"},{"location":"api/#any_agent.tools.MCPConnection.server","title":"<code>server</code>  <code>property</code>","text":"<p>Return the MCP server instance.</p>"},{"location":"api/#any_agent.tools.MCPConnection.list_tools","title":"<code>list_tools()</code>  <code>abstractmethod</code> <code>async</code>","text":"<p>List tools from the MCP server.</p> Source code in <code>src/any_agent/tools/mcp/mcp_connection.py</code> <pre><code>@abstractmethod\nasync def list_tools(self) -&gt; list[Tool]:\n    \"\"\"List tools from the MCP server.\"\"\"\n</code></pre>"},{"location":"api/#any_agent.tools.MCPServerBase","title":"<code>MCPServerBase</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> Source code in <code>src/any_agent/tools/mcp/mcp_server.py</code> <pre><code>class MCPServerBase(BaseModel, ABC):\n    mcp_tool: MCPParams\n    framework: AgentFramework\n    mcp_available: bool = False\n    libraries: str = \"\"\n\n    tools: Sequence[Tool] = Field(default_factory=list)\n    tool_names: Sequence[str] = Field(default_factory=list)\n    mcp_connection: MCPConnection | None = Field(default=None)\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    def model_post_init(self, context: Any) -&gt; None:  # noqa: D102\n        self._check_dependencies()\n\n    @abstractmethod\n    async def _setup_tools(self, mcp_connection: MCPConnection | None = None) -&gt; None:\n        if not mcp_connection:\n            msg = \"MCP server is not set up. Please call `_setup_tools` from a concrete class.\"\n            raise ValueError(msg)\n\n        self.mcp_connection = mcp_connection\n        self.tools = await mcp_connection.list_tools()\n\n    @property\n    def server(self) -&gt; \"MCPServer\":\n        \"\"\"Return the MCP server instance.\"\"\"\n        if not self.mcp_connection or not self.mcp_connection.server:\n            msg = \"MCP server is not set up. Please call `_setup_tools` from a concrete class.\"\n            raise ValueError(msg)\n\n        return self.mcp_connection.server\n\n    @abstractmethod\n    def _check_dependencies(self) -&gt; None:\n        if self.mcp_available:\n            return\n\n        msg = f\"You need to `pip install '{self.libraries}'` to use MCP.\"\n        raise ImportError(msg)\n</code></pre>"},{"location":"api/#any_agent.tools.MCPServerBase.server","title":"<code>server</code>  <code>property</code>","text":"<p>Return the MCP server instance.</p>"},{"location":"api/#any_agent.tools.ask_user_verification","title":"<code>ask_user_verification(query)</code>","text":"<p>Asks user to verify the given <code>query</code>.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question that requires verification.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def ask_user_verification(query: str) -&gt; str:\n    \"\"\"Asks user to verify the given `query`.\n\n    Args:\n        query: The question that requires verification.\n\n    \"\"\"\n    return input(f\"{query} =&gt; Type your answer here:\")\n</code></pre>"},{"location":"api/#any_agent.tools.search_web","title":"<code>search_web(query)</code>","text":"<p>Perform a duckduckgo web search based on your query (think a Google search) then returns the top search results.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The search query to perform.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The top search results.</p> Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def search_web(query: str) -&gt; str:\n    \"\"\"Perform a duckduckgo web search based on your query (think a Google search) then returns the top search results.\n\n    Args:\n        query (str): The search query to perform.\n\n    Returns:\n        The top search results.\n\n    \"\"\"\n    ddgs = DDGS()\n    results = ddgs.text(query, max_results=10)\n    return \"\\n\".join(\n        f\"[{result['title']}]({result['href']})\\n{result['body']}\" for result in results\n    )\n</code></pre>"},{"location":"api/#any_agent.tools.send_console_message","title":"<code>send_console_message(user, query)</code>","text":"<p>Send the specified user a message via console and returns their response.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The question to ask the user.</p> required <code>user</code> <code>str</code> <p>The user to ask the question to.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The user's response.</p> Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def send_console_message(user: str, query: str) -&gt; str:\n    \"\"\"Send the specified user a message via console and returns their response.\n\n    Args:\n        query: The question to ask the user.\n        user: The user to ask the question to.\n\n    Returns:\n        str: The user's response.\n\n    \"\"\"\n    return input(f\"{query}\\n{user}&gt;&gt;\")\n</code></pre>"},{"location":"api/#any_agent.tools.show_final_output","title":"<code>show_final_output(answer)</code>","text":"<p>Show the final answer to the user.</p> <p>Parameters:</p> Name Type Description Default <code>answer</code> <code>str</code> <p>The final answer.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_final_output(answer: str) -&gt; str:\n    \"\"\"Show the final answer to the user.\n\n    Args:\n        answer: The final answer.\n\n    \"\"\"\n    logger.info(f\"Final output: {answer}\")\n    return answer\n</code></pre>"},{"location":"api/#any_agent.tools.show_plan","title":"<code>show_plan(plan)</code>","text":"<p>Show the current plan to the user.</p> <p>Parameters:</p> Name Type Description Default <code>plan</code> <code>str</code> <p>The current plan.</p> required Source code in <code>src/any_agent/tools/user_interaction.py</code> <pre><code>def show_plan(plan: str) -&gt; str:\n    \"\"\"Show the current plan to the user.\n\n    Args:\n        plan: The current plan.\n\n    \"\"\"\n    logger.info(f\"Current plan: {plan}\")\n    return plan\n</code></pre>"},{"location":"api/#any_agent.tools.visit_webpage","title":"<code>visit_webpage(url)</code>","text":"<p>Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The url of the webpage to visit.</p> required Source code in <code>src/any_agent/tools/web_browsing.py</code> <pre><code>def visit_webpage(url: str) -&gt; str:\n    \"\"\"Visits a webpage at the given url and reads its content as a markdown string. Use this to browse webpages.\n\n    Args:\n        url: The url of the webpage to visit.\n\n    \"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n\n        markdown_content = markdownify(response.text).strip()  # type: ignore[no-untyped-call]\n\n        markdown_content = re.sub(r\"\\n{2,}\", \"\\n\", markdown_content)\n\n        return _truncate_content(markdown_content, 10000)\n    except RequestException as e:\n        return f\"Error fetching the webpage: {e!s}\"\n    except Exception as e:\n        return f\"An unexpected error occurred: {e!s}\"\n</code></pre>"},{"location":"api/#any_agent.tracing","title":"<code>any_agent.tracing</code>","text":""},{"location":"api/#any_agent.tracing.TracingProcessor","title":"<code>TracingProcessor</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for processing tracing data from different agent types.</p> Source code in <code>src/any_agent/tracing/processors/base.py</code> <pre><code>class TracingProcessor(ABC):\n    \"\"\"Base class for processing tracing data from different agent types.\"\"\"\n\n    MAX_EVIDENCE_LENGTH: ClassVar[int] = 400\n\n    @classmethod\n    def create(\n        cls, agent_framework_raw: AgentFramework | str\n    ) -&gt; TracingProcessor | None:\n        \"\"\"Create the appropriate tracing processor.\"\"\"\n        agent_framework = AgentFramework.from_string(agent_framework_raw)\n\n        if agent_framework is AgentFramework.LANGCHAIN:\n            from any_agent.tracing.processors.langchain import (\n                LangchainTracingProcessor,\n            )\n\n            return LangchainTracingProcessor()\n        if agent_framework is AgentFramework.SMOLAGENTS:\n            from any_agent.tracing.processors.smolagents import (\n                SmolagentsTracingProcessor,\n            )\n\n            return SmolagentsTracingProcessor()\n        if agent_framework is AgentFramework.OPENAI:\n            from any_agent.tracing.processors.openai import (\n                OpenAITracingProcessor,\n            )\n\n            return OpenAITracingProcessor()\n        if agent_framework is AgentFramework.LLAMA_INDEX:\n            from any_agent.tracing.processors.llama_index import (\n                LlamaIndexTracingProcessor,\n            )\n\n            return LlamaIndexTracingProcessor()\n\n        if (\n            agent_framework is AgentFramework.GOOGLE\n            or agent_framework is AgentFramework.AGNO\n            or agent_framework is AgentFramework.TINYAGENT\n        ):\n            return None\n\n        assert_never(agent_framework)\n\n    @abstractmethod\n    def _extract_hypothesis_answer(self, trace: AgentTrace) -&gt; str:\n        \"\"\"Extract the hypothesis agent final answer from the trace.\"\"\"\n\n    @abstractmethod\n    def _get_agent_framework(self) -&gt; AgentFramework:\n        \"\"\"Get the agent type associated with this processor.\"\"\"\n\n    @abstractmethod\n    def _extract_llm_interaction(self, span: AgentSpan) -&gt; Mapping[str, Any]:\n        \"\"\"Extract interaction details of a span of type LLM.\"\"\"\n\n    @abstractmethod\n    def _extract_tool_interaction(self, span: AgentSpan) -&gt; Mapping[str, Any]:\n        \"\"\"Extract interaction details of a span of type TOOL.\"\"\"\n\n    @abstractmethod\n    def _extract_chain_interaction(self, span: AgentSpan) -&gt; Mapping[str, Any]:\n        \"\"\"Extract interaction details of a span of type CHAIN.\"\"\"\n\n    @abstractmethod\n    def _extract_agent_interaction(self, span: AgentSpan) -&gt; Mapping[str, Any]:\n        \"\"\"Extract interaction details of a span of type AGENT.\"\"\"\n\n    def extract_evidence(self, trace: AgentTrace) -&gt; str:\n        \"\"\"Extract relevant evidence.\"\"\"\n        calls = self._extract_trace_data(trace)\n        return self._format_evidence(calls)\n\n    def _format_evidence(self, calls: Sequence[Mapping[str, Any]]) -&gt; str:\n        \"\"\"Format extracted data into a standardized output format.\"\"\"\n        evidence = f\"## {self._get_agent_framework().name} Agent Execution\\n\\n\"\n\n        for idx, call in enumerate(calls, start=1):\n            evidence += f\"### Call {idx}\\n\"\n\n            # Truncate any values that are too long\n            call = {\n                k: (\n                    v[: self.MAX_EVIDENCE_LENGTH] + \"...\"\n                    if isinstance(v, str) and len(v) &gt; self.MAX_EVIDENCE_LENGTH\n                    else v\n                )\n                for k, v in call.items()\n            }\n\n            # Use ensure_ascii=False to prevent escaping Unicode characters\n            evidence += json.dumps(call, indent=2, ensure_ascii=False) + \"\\n\\n\"\n\n        return evidence\n\n    @staticmethod\n    def parse_generic_key_value_string(text: str) -&gt; dict[str, str]:\n        \"\"\"Parse a string that has items of a dict with key-value pairs separated by '='.\n\n        Only splits on '=' signs, handling quoted strings properly.\n        \"\"\"\n        pattern = r\"(\\w+)=('.*?'|\\\".*?\\\"|[^'\\\"=]*?)(?=\\s+\\w+=|\\s*$)\"\n        result = {}\n\n        matches = re.findall(pattern, text)\n        for key, value in matches:\n            # Clean up the key\n            key = key.strip()\n\n            # Clean up the value - remove surrounding quotes if present\n            if (value.startswith(\"'\") and value.endswith(\"'\")) or (\n                value.startswith('\"') and value.endswith('\"')\n            ):\n                value = value[1:-1]\n\n            # Store in result dictionary\n            result[key] = value\n\n        return result\n\n    def _extract_trace_data(\n        self,\n        trace: AgentTrace,\n    ) -&gt; list[Mapping[str, Any]]:\n        \"\"\"Extract the agent-specific data from trace.\"\"\"\n        calls = []\n\n        for span in trace.spans:\n            calls.append(self.extract_interaction(span)[1])\n\n        return calls\n\n    def extract_interaction(\n        self,\n        span: AgentSpan,\n    ) -&gt; tuple[str, Mapping[str, Any]]:\n        \"\"\"Extract interaction details from a span.\"\"\"\n        span_kind = span.attributes.get(\"openinference.span.kind\", \"\")\n\n        if span_kind == \"LLM\" or \"LiteLLMModel.__call__\" in span.name:\n            return \"LLM\", self._extract_llm_interaction(span)\n        if \"tool.name\" in span.attributes or span.name.endswith(\"Tool\"):\n            return \"TOOL\", self._extract_tool_interaction(span)\n        if span_kind == \"CHAIN\":\n            return \"CHAIN\", self._extract_chain_interaction(span)\n        if span_kind == \"AGENT\":\n            return \"AGENT\", self._extract_agent_interaction(span)\n        logger.warning(f\"Unknown span kind: {span_kind}. Span: {span}\")\n        return \"UNKNOWN\", {}\n</code></pre>"},{"location":"api/#any_agent.tracing.TracingProcessor.create","title":"<code>create(agent_framework_raw)</code>  <code>classmethod</code>","text":"<p>Create the appropriate tracing processor.</p> Source code in <code>src/any_agent/tracing/processors/base.py</code> <pre><code>@classmethod\ndef create(\n    cls, agent_framework_raw: AgentFramework | str\n) -&gt; TracingProcessor | None:\n    \"\"\"Create the appropriate tracing processor.\"\"\"\n    agent_framework = AgentFramework.from_string(agent_framework_raw)\n\n    if agent_framework is AgentFramework.LANGCHAIN:\n        from any_agent.tracing.processors.langchain import (\n            LangchainTracingProcessor,\n        )\n\n        return LangchainTracingProcessor()\n    if agent_framework is AgentFramework.SMOLAGENTS:\n        from any_agent.tracing.processors.smolagents import (\n            SmolagentsTracingProcessor,\n        )\n\n        return SmolagentsTracingProcessor()\n    if agent_framework is AgentFramework.OPENAI:\n        from any_agent.tracing.processors.openai import (\n            OpenAITracingProcessor,\n        )\n\n        return OpenAITracingProcessor()\n    if agent_framework is AgentFramework.LLAMA_INDEX:\n        from any_agent.tracing.processors.llama_index import (\n            LlamaIndexTracingProcessor,\n        )\n\n        return LlamaIndexTracingProcessor()\n\n    if (\n        agent_framework is AgentFramework.GOOGLE\n        or agent_framework is AgentFramework.AGNO\n        or agent_framework is AgentFramework.TINYAGENT\n    ):\n        return None\n\n    assert_never(agent_framework)\n</code></pre>"},{"location":"api/#any_agent.tracing.TracingProcessor.extract_evidence","title":"<code>extract_evidence(trace)</code>","text":"<p>Extract relevant evidence.</p> Source code in <code>src/any_agent/tracing/processors/base.py</code> <pre><code>def extract_evidence(self, trace: AgentTrace) -&gt; str:\n    \"\"\"Extract relevant evidence.\"\"\"\n    calls = self._extract_trace_data(trace)\n    return self._format_evidence(calls)\n</code></pre>"},{"location":"api/#any_agent.tracing.TracingProcessor.extract_interaction","title":"<code>extract_interaction(span)</code>","text":"<p>Extract interaction details from a span.</p> Source code in <code>src/any_agent/tracing/processors/base.py</code> <pre><code>def extract_interaction(\n    self,\n    span: AgentSpan,\n) -&gt; tuple[str, Mapping[str, Any]]:\n    \"\"\"Extract interaction details from a span.\"\"\"\n    span_kind = span.attributes.get(\"openinference.span.kind\", \"\")\n\n    if span_kind == \"LLM\" or \"LiteLLMModel.__call__\" in span.name:\n        return \"LLM\", self._extract_llm_interaction(span)\n    if \"tool.name\" in span.attributes or span.name.endswith(\"Tool\"):\n        return \"TOOL\", self._extract_tool_interaction(span)\n    if span_kind == \"CHAIN\":\n        return \"CHAIN\", self._extract_chain_interaction(span)\n    if span_kind == \"AGENT\":\n        return \"AGENT\", self._extract_agent_interaction(span)\n    logger.warning(f\"Unknown span kind: {span_kind}. Span: {span}\")\n    return \"UNKNOWN\", {}\n</code></pre>"},{"location":"api/#any_agent.tracing.TracingProcessor.parse_generic_key_value_string","title":"<code>parse_generic_key_value_string(text)</code>  <code>staticmethod</code>","text":"<p>Parse a string that has items of a dict with key-value pairs separated by '='.</p> <p>Only splits on '=' signs, handling quoted strings properly.</p> Source code in <code>src/any_agent/tracing/processors/base.py</code> <pre><code>@staticmethod\ndef parse_generic_key_value_string(text: str) -&gt; dict[str, str]:\n    \"\"\"Parse a string that has items of a dict with key-value pairs separated by '='.\n\n    Only splits on '=' signs, handling quoted strings properly.\n    \"\"\"\n    pattern = r\"(\\w+)=('.*?'|\\\".*?\\\"|[^'\\\"=]*?)(?=\\s+\\w+=|\\s*$)\"\n    result = {}\n\n    matches = re.findall(pattern, text)\n    for key, value in matches:\n        # Clean up the key\n        key = key.strip()\n\n        # Clean up the value - remove surrounding quotes if present\n        if (value.startswith(\"'\") and value.endswith(\"'\")) or (\n            value.startswith('\"') and value.endswith('\"')\n        ):\n            value = value[1:-1]\n\n        # Store in result dictionary\n        result[key] = value\n\n    return result\n</code></pre>"},{"location":"evaluation/","title":"Agent Evaluation","text":"<p>Warning</p> <p>The codebase for evaluation is under development and is not yet stable. Use with caution, we welcome contributions.</p> <p>Evaluation using any_agent.evaluation is designed to be a \"trace-first\" evaluation. The evaluation of a trace is not designed to be pass/fail, but is rather a score based on the achievement of user-defined criteria for each example. Agent systems are hyper-specific to each use case, and it's difficult to provide a single set of metrics that would reliably provide the insight needed to make a decision about the effectiveness of an agent.</p> <p>Using any-agent evaluation, you can specify any criteria you wish, and through LLM-as-a-judge technology, any-agent will evaluate which criteria are satisfied.</p>"},{"location":"evaluation/#example","title":"Example","text":"<p>Using the unified tracing format provided by any-agent's tracing functionality, the trace can be evaluated with user defined criteria. The steps for evaluating an agent are as follows:</p>"},{"location":"evaluation/#run-an-agent-using-any-agent-which-will-produce-a-trace-for-example","title":"Run an agent using any-agent, which will produce a trace. For example","text":"<pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4o-mini\",\n        tools=[search_web]\n    ),\n    tracing=TracingConfig(output_dir=\"traces\")\n)\n\nagent_trace = agent.run(\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\")\n</code></pre>"},{"location":"evaluation/#define-an-evaluation-case-either-in-a-yaml-file-or-in-python","title":"Define an evaluation case either in a yaml file or in python:","text":"YAMLPython <p><pre><code># The criteria will be passed to an llm-as-a-judge along with the trace to have as context\n# The points specify the weight given to each criteria when producing the final score\nllm_judge: openai/gpt-4o\ncheckpoints:\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n  - points: 1\n    criteria: Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n  - points: 1\n    criteria: |\n        Ensure that the agent ran a python snippet to combine the information\n        from the info retrieved from the web searches\n\n# Optionally, you can check whether the final answer is what was expected. Checking this value does not use an LLM\nground_truth:\n  - name: Time\n    points: 5\n    value: 9.63\n</code></pre> Then in python <pre><code>from any_agent.evaluation.evaluation_case import EvaluationCase\nevaluation_case = EvaluationCase.from_yaml(evaluation_case_path)\n</code></pre></p> <pre><code>from any_agent.evaluation.evaluation_case import EvaluationCase\nevaluation_case = EvaluationCase(\n        ground_truth=[{\"name\": \"Test Case 1\", \"value\": 1.0, \"points\": 1.0}],\n        checkpoints=[{\"criteria\": \"Check if value is 1.0\", \"points\": 1}],\n        llm_judge=\"gpt-4o-mini\",\n        final_output_criteria=[]\n)\n</code></pre>"},{"location":"evaluation/#run-the-evaluation-using-the-test-case-and-trace","title":"Run the evaluation using the test case and trace.","text":"<p><pre><code>from any_agent.evaluation import EvaluationRunner\nfrom any_agent.evaluation.evaluation_case import EvaluationCase\noutput_path=\"tmp/path/result.json\"\nevaluation_case = EvaluationCase(\n    ground_truth=[{\"name\": \"Test Case 1\", \"value\": 1.0, \"points\": 1.0}],\n    checkpoints=[{\"criteria\": \"Check if value is 1.0\", \"points\": 1}],\n    llm_judge=\"gpt-4o-mini\",\n    final_output_criteria=[]\n)\nrunner = EvaluationRunner(output_path=output_path)\nrunner.add_evaluation_case(evaluation_case)\nrunner.add_trace(agent_trace, 'OPENAI')\nrunner.run()\n</code></pre> The output will look something like this:</p> <pre><code>Passed:\n- Ensure that the agent called the search_web tool in order to retrieve the length of Pont des Arts\n- The agent called the search_web tool with the query 'Pont des Arts length' as indicated in the trace evidence.\n\nPassed:\n- Ensure that the agent ran a python snippet to combine the information from the info retrieved from the web searches\n- The agent successfully ran a Python snippet to calculate the time it would take for a leopard to run through the Pont des Arts using the length of the bridge retrieved from a web search.\n\nFailed:\n- Ensure that the agent called the search_web tool in order to access the top speed of a leopard\n- The agent called the search_web tool to find the length of Pont des Arts, but did not call it to access the top speed of a leopard.\n\nFailed:\n- Check if Time is approximately '9.63'.\n- The calculated time in the agent's answer is 9.62, not 9.63.\n\nFailed:\n- Is the answer a direct match?\n- Partial Match (F1) score is 0.0\nPassed checkpoints: 2\nFailed checkpoints: 3\n=====================================\nScore: 2/9\n=====================================\n\nReading existing output from output/results.json\nWriting output to output/results.json\n</code></pre>"},{"location":"evaluation/#command-line","title":"Command Line","text":"<p>If you have the file and test case prepared, a command line tools is provided for convenience called <code>any-agent-evaluate</code>.</p> <p>It can be called like so</p> <pre><code>any-agent-evaluate \\\n    --evaluation_case_paths=\"['docs/examples/evaluation_case.yaml']\" \\\n    --trace_paths \"['tests/unit/evaluation/sample_traces/OPENAI.json']\" \\\n    --agent_framework 'OPENAI'\n</code></pre>"},{"location":"instructions/","title":"Agent Instructions (aka System Prompt)","text":"<p><code>any-agent</code> allows you to specify the instruction for the agent (often also referred to as a \"system_prompt\").</p> <p>Warning</p> <p>Some frameworks use complex default instructions for specific agent implementations. Completely replacing those instructions might result in unexpected behavior.</p> <p>In those cases, you might want to instead copy-paste and extend the default instructions. For example, check the <code>ToolCallingAgent</code> default instructions in <code>smolagents</code>.</p> <pre><code>from agents.extensions.handoff_prompt import RECOMMENDED_PROMPT_PREFIX\nfrom any_agent import AgentConfig\n\ninstruction = RECOMMENDED_PROMPT_PREFIX + \"\\nYou are a helpful assistant that can navigate the web.\"\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    instructions=instruction,\n)\n</code></pre>"},{"location":"tools/","title":"Agent Tools","text":"<p><code>any-agent</code> provides 2 options to specify what <code>tools</code> are available to your agent: <code>Callable</code>, or <code>MCP</code> (Model Context Protocol).</p> <p>You can use any combination of options in the same agent.</p> <p>Under the hood, <code>any-agent</code> takes care of wrapping the tool so it becomes usable by the selected framework.</p> <p>MCP can either be run locally (MCPStdio) or you can connect to an MCP that is running elsewhere (MCPSse). See SuperGateway for an easy way to turn a Stdio server into an SSE server.</p> CallableMCP (Stdio)MCP (SSE) <pre><code>from any_agent import AgentConfig\nfrom any_agent.tools import search_web\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[search_web]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPStdioParams\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPStdioParams(\n            command=\"docker\",\n            args=[\"run\", \"-i\", \"--rm\", \"mcp/fetch\"],\n            tools=[\"fetch\"]\n        ),\n    ]\n)\n</code></pre> <pre><code>from any_agent import AgentConfig\nfrom any_agent.config import MCPSseParams\n\nmain_agent = AgentConfig(\n    model_id=\"gpt-4o-mini\",\n    tools=[\n        MCPSseParams(\n            url=\"http://localhost:8000/sse\"\n        ),\n    ]\n)\n</code></pre>"},{"location":"tracing/","title":"Agent Tracing","text":"<p><code>any-agent</code> uses <code>openinference</code> to generate standardized OpenTelemetry traces for any of the supported <code>Frameworks</code>.</p>"},{"location":"tracing/#example","title":"Example","text":"<p>To configure tracing, pass a TracingConfig object <code>TracingConfig</code> when creating an agent.</p> <pre><code>from any_agent import AgentConfig, AnyAgent, TracingConfig\nfrom any_agent.tools import search_web\n\nagent = AnyAgent.create(\n        \"openai\",\n        agent_config=AgentConfig(\n                model_id=\"gpt-4o\",\n                tools=[search_web],\n        ),\n        tracing=TracingConfig(console=False)\n      )\nagent_trace = agent.run(\"Which agent framework is the best?\")\n</code></pre>"},{"location":"tracing/#outputs","title":"Outputs","text":"<p>Tracing will output standardized console output regardless of the framework used, and will also save the trace as a json file in the directory set by the TracingConfig object. The file path of the trace is stored in the Agent.trace_filepath member variable.</p> <pre><code>\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 LLM \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ninput: Which agent framework is the best?\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 TOOL \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntool_name: search_web\ninput: {'query': 'best agent framework 2023'}\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Output \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ... The agent architecture came to life in March 2023, but it wasn't until a few    \u2502\n\u2502 months later that it took a grip in the open-source community. The agent landscape may still seem like a \"mad scientist\" kind of experiment, but there are \u2502\n\u2502 already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks Top 10 AI Agent Frameworks - gocodeo.com The    \u2502\n\u2502 ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog     \u2502\n\u2502 Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \"just prompt it and see what happens.\" As AI     \u2502\n\u2502 agents inch closer to production ... List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ... 3. Bee Agent Framework (IBM) Introduction:    \u2502\n\u2502 The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to  \u2502\n\u2502 integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ... Top 9  \u2502\n\u2502 AI Agent Frameworks as of April 2025 | Shakudo AutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by   \u2502\n\u2502 automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build,  \u2502\n\u2502 fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ... 10 best AI    \u2502\n\u2502 agent frameworks - blog.apify.com Best AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a      \u2502\n\u2502 scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it  \u2502\n\u2502 easier to integrate with third-party tools, handle cloud hosting, monitor ... Best 5 Frameworks To Build Multi-Agent AI Applications In this example, we   \u2502\n\u2502 specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run                       \u2502\n\u2502 reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework     \u2502\n\u2502 recently released by OpenAI. It is a lightweight multi-agent orchestration framework. Agentic Framework Showdown: We Tested 8 AI Agent Frameworks They     \u2502\n\u2502 reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of    \u2502\n\u2502 the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI;      \u2502\n\u2502 Langflow; LangGraph; LlamaIndex; n8n ... Comparing Open-Source AI Agent Frameworks - Langfuse Blog This post offers an in-depth look at some of the        \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre> <p>In addition, an output JSON will be stored in the selected <code>output_dir</code>, which is <code>\"traces\"</code> by default:</p> <pre><code>[\n  {\n    \"name\": \"response\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xd4a8cd952e71e1d1\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:25.327409Z\",\n    \"end_time\": \"2025-04-07T10:20:26.813604Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"output.mime_type\": \"application/json\",\n      \"output.value\": \"{\\\"id\\\":\\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\",\\\"created_at\\\":1744021218.0,\\\"error\\\":null,\\\"incomplete_details\\\":null,\\\"instructions\\\":\\\"Search the web to answer\\\",\\\"metadata\\\":{},\\\"model\\\":\\\"gpt-4o-2024-08-06\\\",\\\"object\\\":\\\"response\\\",\\\"output\\\":[{\\\"arguments\\\":\\\"{\\\\\\\"query\\\\\\\":\\\\\\\"best agent framework 2023\\\\\\\"}\\\",\\\"call_id\\\":\\\"call_xCZMfOtnbmKS1nGDywFtmCcR\\\",\\\"name\\\":\\\"search_web\\\",\\\"type\\\":\\\"function_call\\\",\\\"id\\\":\\\"fc_67f3a6e351988192a79ec42d68fccbe001e7f8b6e38c7e7a\\\",\\\"status\\\":\\\"completed\\\"}],\\\"parallel_tool_calls\\\":false,\\\"temperature\\\":1.0,\\\"tool_choice\\\":\\\"auto\\\",\\\"tools\\\":[{\\\"name\\\":\\\"search_web\\\",\\\"parameters\\\":{\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"The search query to perform.\\\",\\\"title\\\":\\\"Query\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"],\\\"title\\\":\\\"search_web_args\\\",\\\"type\\\":\\\"object\\\",\\\"additionalProperties\\\":false},\\\"strict\\\":true,\\\"type\\\":\\\"function\\\",\\\"description\\\":\\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\"}],\\\"top_p\\\":1.0,\\\"max_output_tokens\\\":null,\\\"previous_response_id\\\":null,\\\"reasoning\\\":{\\\"effort\\\":null,\\\"generate_summary\\\":null},\\\"status\\\":\\\"completed\\\",\\\"text\\\":{\\\"format\\\":{\\\"type\\\":\\\"text\\\"}},\\\"truncation\\\":\\\"disabled\\\",\\\"usage\\\":{\\\"input_tokens\\\":89,\\\"input_tokens_details\\\":{\\\"cached_tokens\\\":0},\\\"output_tokens\\\":20,\\\"output_tokens_details\\\":{\\\"reasoning_tokens\\\":0},\\\"total_tokens\\\":109},\\\"user\\\":null,\\\"store\\\":true}\",\n      \"llm.tools.0.tool.json_schema\": \"{\\\"type\\\": \\\"function\\\", \\\"function\\\": {\\\"name\\\": \\\"search_web\\\", \\\"description\\\": \\\"Performs a duckduckgo web search based on your query (think a Google search) then returns the top search results.\\\", \\\"parameters\\\": {\\\"properties\\\": {\\\"query\\\": {\\\"description\\\": \\\"The search query to perform.\\\", \\\"title\\\": \\\"Query\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"query\\\"], \\\"title\\\": \\\"search_web_args\\\", \\\"type\\\": \\\"object\\\", \\\"additionalProperties\\\": false}, \\\"strict\\\": true}}\",\n      \"llm.token_count.completion\": 89,\n      \"llm.token_count.prompt\": 20,\n      \"llm.token_count.total\": 109,\n      \"llm.output_messages.0.message.role\": \"assistant\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.id\": \"call_xCZMfOtnbmKS1nGDywFtmCcR\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.name\": \"search_web\",\n      \"llm.output_messages.0.message.tool_calls.0.tool_call.function.arguments\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"llm.input_messages.0.message.role\": \"system\",\n      \"llm.input_messages.0.message.content\": \"Search the web to answer\",\n      \"llm.model_name\": \"gpt-4o-2024-08-06\",\n      \"llm.invocation_parameters\": \"{\\\"id\\\": \\\"resp_67f3a6e2d1dc8192b7d68b130f05f79801e7f8b6e38c7e7a\\\", \\\"created_at\\\": 1744021218.0, \\\"instructions\\\": \\\"Search the web to answer\\\", \\\"metadata\\\": {}, \\\"model\\\": \\\"gpt-4o-2024-08-06\\\", \\\"object\\\": \\\"response\\\", \\\"parallel_tool_calls\\\": false, \\\"temperature\\\": 1.0, \\\"tool_choice\\\": \\\"auto\\\", \\\"top_p\\\": 1.0, \\\"reasoning\\\": {}, \\\"status\\\": \\\"completed\\\", \\\"text\\\": {\\\"format\\\": {\\\"type\\\": \\\"text\\\"}}, \\\"truncation\\\": \\\"disabled\\\", \\\"store\\\": true}\",\n      \"input.mime_type\": \"application/json\",\n      \"input.value\": \"[{\\\"content\\\": \\\"Which agent framework is the best?\\\", \\\"role\\\": \\\"user\\\"}]\",\n      \"llm.input_messages.1.message.role\": \"user\",\n      \"llm.input_messages.1.message.content\": \"Which agent framework is the best?\",\n      \"openinference.span.kind\": \"LLM\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n  {\n    \"name\": \"search_web\",\n    \"context\": {\n      \"trace_id\": \"0x1ee8d988d05d9c2e64a456dcccbf7a3c\",\n      \"span_id\": \"0xe8fa92007caee376\",\n      \"trace_state\": \"[]\"\n    },\n    \"kind\": \"SpanKind.INTERNAL\",\n    \"parent_id\": \"0xbea970a46577575a\",\n    \"start_time\": \"2025-04-07T10:20:26.821732Z\",\n    \"end_time\": \"2025-04-07T10:20:28.420378Z\",\n    \"status\": {\n      \"status_code\": \"UNSET\"\n    },\n    \"attributes\": {\n      \"llm.system\": \"openai\",\n      \"tool.name\": \"search_web\",\n      \"input.value\": \"{\\\"query\\\":\\\"best agent framework 2023\\\"}\",\n      \"input.mime_type\": \"application/json\",\n      \"output.value\": \"[Top 12 Open-Source Autonomous Agents &amp; Agent Frameworks: The Future of ...](https://www.taskade.com/blog/top-autonomous-agents/)\\nThe agent architecture came to life in March 2023, but it wasn't until a few months later that it took a grip in the open-source community. The agent landscape may still seem like a \\\"mad scientist\\\" kind of experiment, but there are already a few insanely powerful models you can try. Top Open Source Autonomous Agents and Agent Frameworks\\n[Top 10 AI Agent Frameworks - gocodeo.com](https://www.gocodeo.com/post/top-10-ai-agent-frameworks)\\nThe ultimate guide to AI agent frameworks, compare the best tools for building, scaling, and orchestrating intelligent systems. Features Pricing Docs Blog Support. Install Now. Top 10 AI Agent Frameworks. Written By: April 4, 2025. We're well past the phase of \\\"just prompt it and see what happens.\\\" As AI agents inch closer to production ...\\n[List of Top 10 Multi-Agent Orchestrator Frameworks for Deploying AI ...](https://www.devopsschool.com/blog/list-of-top-10-multi-agent-orchestrator-frameworks-for-deploying-ai-agents/)\\n3. Bee Agent Framework (IBM) Introduction: The Bee Agent Framework by IBM is a modular and enterprise-focused orchestration platform for managing large-scale multi-agent systems. It is designed to integrate with IBM's AI solutions for optimized workflows and analytics. Features: Modular Architecture: Plug-and-play functionality for custom ...\\n[Top 9 AI Agent Frameworks as of April 2025 | Shakudo](https://www.shakudo.io/blog/top-9-ai-agent-frameworks)\\nAutoGen is a framework developed by Microsoft that facilitates the creation of AI-powered applications by automating the generation of code, models, and processes needed for complex workflows.It leverages large language models (LLMs) to help developers build, fine-tune, and deploy AI solutions with minimal manual coding. AutoGen is particularly effective at automating the process of generating ...\\n[10 best AI agent frameworks - blog.apify.com](https://blog.apify.com/10-best-ai-agent-frameworks/)\\nBest AI agent framework platforms. AI agent frameworks are just one piece of the puzzle when it comes to building a scalable, commercially viable AI application. Fully featured platforms do more than just offer tooling to facilitate agent development, they also make it easier to integrate with third-party tools, handle cloud hosting, monitor ...\\n[Best 5 Frameworks To Build Multi-Agent AI Applications](https://getstream.io/blog/multiagent-ai-frameworks/)\\nIn this example, we specify the prompt task as the code shows. Then, we create a new agent with reasoning=True to make it a thinking agent. When you run reasoning_ai_agent.py, you should see a result similar to the preview below.. 2. OpenAI Swarm. Swarm is an open-source, experimental agentic framework recently released by OpenAI. It is a lightweight multi-agent orchestration framework.\\n[Agentic Framework Showdown: We Tested 8 AI Agent Frameworks](https://www.willowtreeapps.com/craft/8-agentic-frameworks-tested)\\nThey reduce complexity and streamline decision-making as we build our agents. To find the best agentic framework for our client projects, we tested eight of the most promising AI agent frameworks currently available, some relative newborns at less than six months from their first release: Autogen; CrewAI; Langflow; LangGraph; LlamaIndex; n8n ...\\n[Comparing Open-Source AI Agent Frameworks - Langfuse Blog](https://langfuse.com/blog/2025-03-19-ai-agent-comparison)\\nThis post offers an in-depth look at some of the leading open-source AI agent frameworks out there: LangGraph, the OpenAI Agents SDK, Smolagents, CrewAI, AutoGen, Semantic Kernel, and LlamaIndex agents. By the time you finish reading, you should have a clearer view of each framework's sweet spot, how they differ, and where they excel in real ...\\n[Choosing the Right AI Agent Framework: LangGraph vs CrewAI vs OpenAI Swarm](https://www.relari.ai/blog/ai-agent-framework-comparison-langgraph-crewai-openai-swarm)\\nWe chose LangGraph, CrewAI, and OpenAI Swarm because they represent the latest schools of thought in agent development. Here's a quick overview: LangGraph: As its name suggests, LangGraph bets on graph architecture as the best way to define and orchestrate agentic workflows. Unlike early versions of LangChain, LangGraph is a well designed framework with many robust and customizable features ...\\n[Best AI Agent Frameworks](https://www.folio3.ai/blog/ai-agent-frameworks/)\\nYour business demands the best AI agent framework to accelerate your project. It should support LLM integration, advanced reasoning, long-term memory, flexible tool coordination, and smooth collaboration between multiple agents. Here we discuss some AI agent frameworks that empower you to achieve unmatched levels of automation and intelligence.\",\n      \"openinference.span.kind\": \"TOOL\"\n    },\n    \"events\": [],\n    \"links\": [],\n    \"resource\": {\n      \"attributes\": {\n        \"telemetry.sdk.language\": \"python\",\n        \"telemetry.sdk.name\": \"opentelemetry\",\n        \"telemetry.sdk.version\": \"1.31.1\",\n        \"service.name\": \"unknown_service\"\n      },\n      \"schema_url\": \"\"\n    }\n  },\n</code></pre>"},{"location":"frameworks/agno/","title":"Agno","text":"<p>https://github.com/agno-agi/agno</p>"},{"location":"frameworks/agno/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>agno.agent.Agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/agno/#default-model-type","title":"Default Model Type","text":"<p>We use <code>agno.models.litellm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/agno/#examples","title":"Examples","text":""},{"location":"frameworks/agno/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"agno\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    ),\n    agent_args={\n        \"tool_call_limit\": 3\n    }\n)\nagent.run(\"Which Agent Framework is the best??\")\n</code></pre>"},{"location":"frameworks/google_adk/","title":"Google Agent Development Kit (ADK)","text":"<p>https://github.com/google/adk-python</p>"},{"location":"frameworks/google_adk/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>google.adk.agents.llm_agent.LlmAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/google_adk/#default-model-type","title":"Default Model Type","text":"<p>We use <code>google.adk.models.lite_llm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/google_adk/#run-args","title":"Run args","text":"<p>Check <code>RunConfig</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/google_adk/#examples","title":"Examples","text":""},{"location":"frameworks/google_adk/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\nfrom google.adk.agents.run_config import RunConfig\n\nagent = AnyAgent.create(\n    \"google\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    run_config=RunConfig(\n        max_llm_calls=3\n    )\n)\n</code></pre>"},{"location":"frameworks/langchain/","title":"LangChain","text":"<p>https://github.com/langchain-ai/langchain</p> <p>https://github.com/langchain-ai/langgraph</p>"},{"location":"frameworks/langchain/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>langgraph.prebuilt.create_react_agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/langchain/#default-model-type","title":"Default Model Type","text":"<p>We use <code>langchain_litellm.ChatLiteLLM</code> Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/langchain/#run-args","title":"Run args","text":"<p>Check <code>RunnableConfig</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/langchain/#examples","title":"Examples","text":""},{"location":"frameworks/langchain/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\nfrom langchain_core.runnables import RunnableConfig\n\nagent = AnyAgent.create(\n    \"langchain\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    config=RunnableConfig(\n        recursion_limit=3\n    )\n)\n</code></pre>"},{"location":"frameworks/llama_index/","title":"LlamaIndex","text":"<p>https://github.com/run-llama/llama_index</p>"},{"location":"frameworks/llama_index/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>llama_index.core.agent.workflow.react_agent.ReActAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/llama_index/#default-model-type","title":"Default Model Type","text":"<p>We use <code>llama_index.llms.litellm.LiteLLM</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/llama_index/#examples","title":"Examples","text":""},{"location":"frameworks/llama_index/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<p>Pending on https://github.com/run-llama/llama_index/issues/18535</p>"},{"location":"frameworks/openai/","title":"OpenAI Agents SDK","text":"<p>https://github.com/openai/openai-agents-python</p>"},{"location":"frameworks/openai/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>agents.Agent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/openai/#default-model-type","title":"Default Model Type","text":"<p>We use <code>agents.extensions.models.litellm_model.LitellmModel</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/openai/#run-args","title":"Run args","text":"<p>Check <code>agents.run.Runner.run</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/openai/#examples","title":"Examples","text":""},{"location":"frameworks/openai/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"openai\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    max_turns=3\n)\n</code></pre>"},{"location":"frameworks/smolagents/","title":"smolagents","text":"<p>https://github.com/huggingface/smolagents</p>"},{"location":"frameworks/smolagents/#default-agent-type","title":"Default Agent Type","text":"<p>We use <code>smolagents.CodeAgent</code> as default. Check the reference to find additional supported <code>agent_args</code>.</p>"},{"location":"frameworks/smolagents/#default-model-type","title":"Default Model Type","text":"<p>We use <code>smolagents.LiteLLMModel</code> as default. Check the reference to find additional supported <code>model_args</code>.</p>"},{"location":"frameworks/smolagents/#run-args","title":"Run args","text":"<p>Check <code>smolagents.MultiStepAgent.run</code> to find additional supported <code>AnyAgent.run</code> args.</p>"},{"location":"frameworks/smolagents/#examples","title":"Examples","text":""},{"location":"frameworks/smolagents/#limiting-the-number-of-steps","title":"Limiting the number of steps","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.tools import search_web, visit_webpage\n\nagent = AnyAgent.create(\n    \"smolagents\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[search_web, visit_webpage]\n    )\n)\n\nagent.run(\n    \"Which Agent Framework is the best??\",\n    max_steps=3\n)\n</code></pre>"},{"location":"frameworks/tinyagent/","title":"TinyAgent","text":"<p>As part of the bare bones library, we provide our own Python implementation based on HuggingFace Tiny Agents.</p> <p>You can find it in <code>any_agent.frameworks.tinyagent</code>.</p>"},{"location":"frameworks/tinyagent/#examples","title":"Examples","text":""},{"location":"frameworks/tinyagent/#use-mcp-tools","title":"Use MCP Tools","text":"<pre><code>from any_agent import AnyAgent, AgentConfig\nfrom any_agent.config import MCPStdioParams\n\nagent = AnyAgent.create(\n    \"tinyagent\",\n    AgentConfig(\n        model_id=\"gpt-4.1-nano\",\n        instructions=\"You must use the available tools to find an answer\",\n        tools=[\n            MCPStdioParams(\n                command=\"uvx\",\n                args=[\"duckduckgo-mcp-server\"]\n            )\n        ]\n    )\n)\n\nresult = agent.run(\n    \"Which Agent Framework is the best??\"\n)\nprint(result.final_output)\n</code></pre>"}]}